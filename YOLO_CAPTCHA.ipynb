{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_CAPTCHA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "SG15RsvpbZVB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 uninstall pytorch-hrvvi-ext -y\n",
        "!pip3 install -U git+https://github.com/sbl1996/pytorch-hrvvi-ext.git\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hYoZ6GBgbagm",
        "outputId": "0ce5e7e0-f023-4cc1-c622-a810ecc4b881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import hutil\n",
        "import matplotlib.pyplot as plt\n",
        "print(hutil.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fQPs47lgEFMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YjUdIrJusmXI",
        "outputId": "6d626f79-d8e0-48a0-a513-efb01c647538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "gdrive = \"/gdrive\"\n",
        "from google.colab import drive\n",
        "drive.mount(gdrive, force_remount=True)\n",
        "mydrive = os.path.join(gdrive, \"My Drive\")\n",
        "!ls /gdrive/My\\ Drive\n",
        "\n",
        "def gpath(p):\n",
        "    return os.path.join(mydrive, p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "'Colab Notebooks'   eng-fra.pt\t images   repo\t   weixin.pkl\n",
            " datasets\t    fonts\t models   result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XE5n0hZL0dNg",
        "colab_type": "code",
        "outputId": "201b9c96-35de-498d-d186-c70c367bfcdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import LambdaLR, MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from hutil import cuda, one_hot\n",
        "from hutil.train import init_weights, Trainer\n",
        "from hutil.data import train_test_split, Fullset\n",
        "from hutil.transforms.detection import Compose, Resize, CenterCrop, ToTensor, ToPercentCoords\n",
        "from hutil.ext.captcha import ImageCaptcha\n",
        "from hutil.datasets import CaptchaDetectionOnline\n",
        "from hutil.train.metrics import TrainLoss, MeanAveragePrecision\n",
        "from hutil.detection import BBox, box_collate_fn, transform_bboxes, transform_bbox, iou_1m, non_max_suppression\n",
        "from hutil.ext.summary import summary\n",
        "from hutil.inference import freeze\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "â–ˆ\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tuBNyhdMSp4d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def get_anchors(lx, ly, priors):\n",
        "    anchors = torch.zeros(lx, ly, len(priors), 4)\n",
        "    anchors[:, :, :, 0] = (torch.arange(\n",
        "        lx, dtype=torch.float).view(lx, 1, 1).expand(lx, ly, len(priors)) + 0.5) / lx\n",
        "    anchors[:, :, :, 1] = (torch.arange(\n",
        "        ly, dtype=torch.float).view(1, ly, 1).expand(lx, ly, len(priors)) + 0.5) / ly\n",
        "    anchors[:, :, :, 2:] = priors / torch.FloatTensor([lx, ly])\n",
        "    return anchors\n",
        "\n",
        "\n",
        "def inverse_sigmoid(x):\n",
        "    x = min(max(x, .01), .99)\n",
        "    return math.log(x / (1 - x))\n",
        "\n",
        "\n",
        "def scale_boxes(boxes, width, height, inplace=False):\n",
        "    r\"\"\"\n",
        "    Args:\n",
        "        boxes: (lx, ly, num_priors, 4)\n",
        "    \"\"\"\n",
        "    if not inplace:\n",
        "        boxes = boxes.clone()\n",
        "    lx, ly = boxes.shape[:2]\n",
        "    sw = width / lx\n",
        "    sh = height / ly\n",
        "    offset_x = torch.arange(\n",
        "        lx, dtype=boxes.dtype, device=boxes.device).view(-1, 1, 1)\n",
        "    boxes[..., 0] += offset_x\n",
        "    boxes[..., [0, 2]] *= sw\n",
        "\n",
        "    offset_y = torch.arange(\n",
        "        ly, dtype=boxes.dtype, device=boxes.device).view(1, -1, 1)\n",
        "    boxes[..., 1] += offset_y\n",
        "    boxes[..., [1, 3]] *= sh\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def filter_tensors(*tensors, indices):\n",
        "    return [t[indices] for t in tensors]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iZnUkMJNHTBx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class YOLOTransform:\n",
        "\n",
        "    def __init__(self, f_anchors, num_classes, ignore_threshold=0.5, get_label=get(\"category_id\"), get_bbox=get(\"bbox\"), label_offset=0):\n",
        "        self.f_anchors = f_anchors\n",
        "        self.num_classes = num_classes\n",
        "        self.ignore_threshold = ignore_threshold\n",
        "        self.get_label = get_label\n",
        "        self.get_bbox = get_bbox\n",
        "        self.label_offset = label_offset\n",
        "\n",
        "    def __call__(self, img, anns):\n",
        "        num_feature_maps = len(self.f_anchors)\n",
        "        locations = []\n",
        "        f_anchors = []\n",
        "        loc_targets = []\n",
        "        cls_targets = []\n",
        "        iou_masks = []\n",
        "\n",
        "        for anchors in self.f_anchors:\n",
        "            locations.append(anchors.size()[:2])\n",
        "            anchors = anchors.view(-1, 4)\n",
        "            num_anchors = anchors.size(0)\n",
        "            f_anchors.append(anchors)\n",
        "            loc_targets.append(torch.zeros(num_anchors, 4))\n",
        "            cls_targets.append(torch.zeros(num_anchors, dtype=torch.long))\n",
        "            iou_masks.append(torch.zeros(num_anchors, dtype=torch.uint8))\n",
        "\n",
        "        for ann in anns:\n",
        "            label = self.get_label(ann) + self.label_offset\n",
        "            l, t, w, h = self.get_bbox(ann)\n",
        "            x = l + w / 2\n",
        "            y = t + h / 2\n",
        "            bbox = torch.tensor([x, y, w, h])\n",
        "\n",
        "            max_ious = []\n",
        "            for anchors, loc_t, cls_t, iou_mask in zip(f_anchors, loc_targets, cls_targets, iou_masks):\n",
        "                ious = iou_1m(bbox, anchors, BBox.XYWH)\n",
        "                max_ious.append(ious.max(dim=0))\n",
        "\n",
        "                iou_mask |= ious > self.ignore_threshold\n",
        "\n",
        "            f_i, (max_iou, i) = max(\n",
        "                enumerate(max_ious), key=lambda x: x[1][0])\n",
        "            lx, ly = locations[f_i]\n",
        "            loc_targets[f_i][i, 0] = inverse_sigmoid(x * lx % 1)\n",
        "            loc_targets[f_i][i, 1] = inverse_sigmoid(y * ly % 1)\n",
        "            loc_targets[f_i][i, 2:] = (bbox[2:] / f_anchors[f_i][i, 2:]).log()\n",
        "            cls_targets[f_i][i] = label\n",
        "\n",
        "        return img, [loc_targets, cls_targets, iou_masks]\n",
        "\n",
        "\n",
        "class YOLOLoss(nn.Module):\n",
        "    def __init__(self, num_classes, p=0.01):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, ps, loc_target, cls_target, iou_masks):\n",
        "        total_pos = 0\n",
        "        obj_loss_pos = 0\n",
        "        obj_loss_neg = 0\n",
        "        loc_loss = 0\n",
        "        cls_loss = 0\n",
        "        for p, loc_t, cls_t, iou_mask in zip(ps, loc_target, cls_target, iou_masks):\n",
        "            p = p.view(p.size(0), -1, 5 + self.num_classes)\n",
        "            obj_p = p[..., 0]\n",
        "            loc_p = p[..., 1:5]\n",
        "            # p[..., 5] is the background class\n",
        "            cls_p = p[..., 6:]\n",
        "\n",
        "            pos = cls_t != 0\n",
        "            num_pos = pos.sum().item()\n",
        "            total_pos += num_pos\n",
        "            cls_t = one_hot(cls_t, self.num_classes)[..., 1:]\n",
        "            obj_p_pos = obj_p[pos]\n",
        "            obj_loss_pos += F.binary_cross_entropy_with_logits(\n",
        "                obj_p_pos, torch.ones_like(obj_p_pos), reduction='sum'\n",
        "            )\n",
        "            obj_p_neg = obj_p[~pos & ~iou_mask]\n",
        "            obj_loss_neg += F.binary_cross_entropy_with_logits(\n",
        "                obj_p_neg, torch.zeros_like(obj_p_neg), reduction='sum'\n",
        "            )\n",
        "\n",
        "            if num_pos == 0:\n",
        "                continue\n",
        "\n",
        "            loc_loss += F.mse_loss(\n",
        "                loc_p[pos], loc_t[pos], reduction='sum')\n",
        "            cls_loss += F.binary_cross_entropy_with_logits(\n",
        "                cls_p[pos], cls_t[pos], reduction='sum')\n",
        "\n",
        "        obj_loss_neg = 0.5 * obj_loss_neg\n",
        "        # loc_loss = 5 * loc_loss\n",
        "        loss = (obj_loss_pos + obj_loss_neg + loc_loss + cls_loss) / total_pos\n",
        "        if random.random() < self.p:\n",
        "            print(\"pos: %.4f | neg: %.4f | loc: %.4f | cls: %.4f\" %\n",
        "                  (obj_loss_pos.item() / total_pos,\n",
        "                   obj_loss_neg.item() / total_pos,\n",
        "                   loc_loss.item() / total_pos,\n",
        "                   cls_loss.item() / total_pos))\n",
        "        return loss\n",
        "\n",
        "class YOLOInference:\n",
        "\n",
        "    def __init__(self, width, height, f_priors, conf_threshold=0.5, iou_threshold=0.5, topk=10):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.f_priors = f_priors\n",
        "        self.conf_threshold = conf_threshold\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.topk = topk\n",
        "\n",
        "    def __call__(self, preds):\n",
        "        detections = []\n",
        "        batch_size = preds[0].size(0)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            confs = []\n",
        "            boxes = []\n",
        "            labels = []\n",
        "            for p, priors in zip(preds, self.f_priors):\n",
        "                p = p[i]\n",
        "                lx, ly = p.size()[:2]\n",
        "                p = p.view(lx, ly, len(priors), -1)\n",
        "                conf = p[..., 0].sigmoid_()\n",
        "                box = p[..., 1:5]\n",
        "                box[..., :2].sigmoid_()\n",
        "                box[..., 2:].exp_().mul_(priors)\n",
        "                box = scale_boxes(box, self.width, self.height)\n",
        "                # p[..., 5] is the background class\n",
        "                label = p[..., 6:].argmax(dim=-1)\n",
        "\n",
        "                mask = conf > self.conf_threshold\n",
        "                conf = conf[mask]\n",
        "                box = box[mask]\n",
        "                label = label[mask]\n",
        "\n",
        "                confs.append(conf)\n",
        "                boxes.append(box)\n",
        "                labels.append(label)\n",
        "\n",
        "            boxes = torch.cat(boxes, dim=0)\n",
        "            confs = torch.cat(confs, dim=0)\n",
        "            labels = torch.cat(labels, dim=0)\n",
        "\n",
        "            boxes = transform_bboxes(\n",
        "                boxes, format=BBox.XYWH, to=BBox.LTRB, inplace=True)\n",
        "            indices = non_max_suppression(\n",
        "                boxes, confs, self.iou_threshold)\n",
        "\n",
        "            if len(indices) > self.topk:\n",
        "                confs, boxes, labels = filter_tensors(\n",
        "                    confs, boxes, labels, indices=indices\n",
        "                )\n",
        "                indices = confs.topk(self.topk)[1]\n",
        "\n",
        "            dets = [\n",
        "                BBox(\n",
        "                    image_name=i,\n",
        "                    class_id=labels[ind].item(),\n",
        "                    box=boxes[ind].tolist(),\n",
        "                    confidence=confs[ind].item(),\n",
        "                    box_format=BBox.LTRB,\n",
        "                ) for ind in indices\n",
        "            ]\n",
        "            detections += dets\n",
        "        return detections\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ORkJGFiJWKmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def conv1x1(in_channels, out_channels):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "\n",
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, residual=True):\n",
        "        super().__init__()\n",
        "        self.residual = residual\n",
        "        self.conv1 = nn.Sequential(\n",
        "            conv1x1(in_channels, out_channels // 2),\n",
        "            nn.BatchNorm2d(out_channels // 2),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            conv3x3(out_channels // 2, out_channels),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return x + identity if self.residual else x\n",
        "\n",
        "\n",
        "def _make_layer(num_layers, in_channels, out_channels):\n",
        "    layers = []\n",
        "    layers.append(Bottleneck(in_channels, out_channels))\n",
        "    for _ in range(num_layers - 1):\n",
        "        layers.append(Bottleneck(out_channels, out_channels))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def _upsample_concat(x, y):\n",
        "    h, w = y.size()[2:]\n",
        "    x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=False)\n",
        "    return torch.cat((x, y), dim=1)\n",
        "\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels=None):\n",
        "        super().__init__()\n",
        "        if out_channels is None:\n",
        "            out_channels = in_channels\n",
        "            in_channels = in_channels // 2\n",
        "        self.down = nn.Sequential(\n",
        "            conv3x3(in_channels, out_channels, stride=2),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down(x)\n",
        "\n",
        "\n",
        "class Darknet(nn.Module):\n",
        "    def __init__(self, out_channels, layers=[1, 2, 8, 8, 4], f_channels=128):\n",
        "        super().__init__()\n",
        "        self.conv0 = nn.Sequential(\n",
        "            conv3x3(3, 32),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "        self.down1 = Downsample(64)\n",
        "        self.layer1 = _make_layer(layers[0], 64, 64)\n",
        "\n",
        "        self.down2 = Downsample(64, f_channels * 1)\n",
        "        self.layer2 = _make_layer(layers[1], f_channels * 1, f_channels * 1)\n",
        "\n",
        "        self.down3 = Downsample(f_channels * 2)\n",
        "        self.layer3 = _make_layer(layers[2], f_channels * 2, f_channels * 2)\n",
        "\n",
        "        self.down4 = Downsample(f_channels * 4)\n",
        "        self.layer4 = _make_layer(layers[3], f_channels * 4, f_channels * 4)\n",
        "\n",
        "        # self.down5 = Downsample(f_channels * 8)\n",
        "        # self.layer5 = _make_layer(layers[4], f_channels * 8, f_channels * 8)\n",
        "\n",
        "        self.conv1 = Bottleneck(f_channels * 4,\n",
        "                                f_channels * 4, residual=False)\n",
        "        self.conv2 = Bottleneck(f_channels * 4, f_channels * 4, residual=False)\n",
        "        self.conv3 = Bottleneck(f_channels * 4, f_channels * 4, residual=False)\n",
        "        self.pred1 = conv1x1(f_channels * 4, out_channels)\n",
        "\n",
        "        self.lat1 = conv1x1(f_channels * 4, f_channels)\n",
        "\n",
        "        self.conv4 = Bottleneck(f_channels * 3,\n",
        "                                f_channels * 2, residual=False)\n",
        "        self.conv5 = Bottleneck(f_channels * 2, f_channels * 2, residual=False)\n",
        "        self.conv6 = Bottleneck(f_channels * 2, f_channels * 2, residual=False)\n",
        "        self.pred2 = conv1x1(f_channels * 2, out_channels)\n",
        "\n",
        "        # self.lat2 = conv1x1(f_channels * 4, f_channels)\n",
        "\n",
        "        # self.conv7 = Bottleneck(f_channels * 3,\n",
        "        #                         f_channels * 2, residual=False)\n",
        "        # self.conv8 = Bottleneck(f_channels * 2, f_channels * 2, residual=False)\n",
        "        # self.conv9 = Bottleneck(f_channels * 2, f_channels * 2, residual=False)\n",
        "        # self.pred3 = conv1x1(f_channels * 2, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv0(x)\n",
        "        c1 = self.down1(x)\n",
        "        c1 = self.layer1(c1)\n",
        "\n",
        "        c2 = self.down2(c1)\n",
        "        c2 = self.layer2(c2)\n",
        "\n",
        "        c3 = self.down3(c2)\n",
        "        c3 = self.layer3(c3)\n",
        "\n",
        "        c4 = self.down4(c3)\n",
        "        c4 = self.layer4(c4)\n",
        "\n",
        "        # c5 = self.down5(c4)\n",
        "        # c5 = self.layer5(c5)\n",
        "\n",
        "        p41 = self.conv1(c4)\n",
        "        p42 = self.conv2(p41)\n",
        "        p43 = self.conv3(p42)\n",
        "        p4 = self.pred1(p43)\n",
        "\n",
        "        c3 = _upsample_concat(self.lat1(p42), c3)\n",
        "        p31 = self.conv4(c3)\n",
        "        p32 = self.conv5(p31)\n",
        "        p33 = self.conv6(p32)\n",
        "        p3 = self.pred2(p33)\n",
        "\n",
        "        # c3 = _upsample_concat(self.lat2(p42), c3)\n",
        "        # p31 = self.conv7(c3)\n",
        "        # p32 = self.conv8(p31)\n",
        "        # p33 = self.conv9(p32)\n",
        "        # p3 = self.pred3(p33)\n",
        "\n",
        "        preds = [p3, p4]\n",
        "        preds = [p.permute(0, 3, 2, 1).contiguous() for p in preds]\n",
        "\n",
        "        return [preds]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xNpK9h-iLMQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# letters = \"0123456789\"\n",
        "letters = \"0123456789abcdefghijkmnopqrstuvwxyzABDEFGHJKMNRT\"\n",
        "NUM_CLASSES = len(letters)\n",
        "WIDTH = 128\n",
        "HEIGHT = 48\n",
        "LOCATIONS = [\n",
        "    (16, 6),\n",
        "    (8, 3),\n",
        "]\n",
        "PRIORS = torch.tensor([\n",
        "    [\n",
        "        [3.9506, 5.1250],\n",
        "        [2.1728, 4.8126],\n",
        "        [2.8750, 3.7504],\n",
        "    ],\n",
        "    [\n",
        "        [1.9753, 2.5625],\n",
        "        [1.0864, 2.4063],\n",
        "        [1.4375, 1.8752],\n",
        "    ],\n",
        "])\n",
        "F_ANCHORS = [\n",
        "    get_anchors(lx, ly, priors)\n",
        "    for (lx, ly), priors in zip(LOCATIONS, F_PRIORS)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cj2oL90kEdRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "fonts = [\n",
        "    gpath(\"fonts/msyh.ttf\"),\n",
        "    gpath(\"fonts/sfsl0800.pfb.ttf\"),\n",
        "    gpath(\"fonts/SimHei.ttf\"),\n",
        "    gpath(\"fonts/Times New Roman.ttf\"),\n",
        "]\n",
        "\n",
        "font_sizes = (28, 32, 36, 40, 44)\n",
        "image = ImageCaptcha(WIDTH, HEIGHT, fonts=fonts, font_sizes=font_sizes)\n",
        "\n",
        "train_transform = Compose([\n",
        "    ToPercentCoords(),\n",
        "    YOLOTransform(F_ANCHORS, NUM_CLASSES, label_offset=1),\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "ds_train = CaptchaDetectionOnline(\n",
        "    image, size=10000, letters=letters, transform=train_transform, rotate=20)\n",
        "ds_val = CaptchaDetectionOnline(\n",
        "    image, size=500, letters=letters, transform=test_transform, online=False, rotate=20)\n",
        "\n",
        "\n",
        "# ds = CaptchaDetectionOnline(\n",
        "#     image, size=100, letters=letters, rotate=20)\n",
        "# ds_train = Fullset(ds, train_transform)\n",
        "# ds_val = Fullset(ds, test_transform)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oBvH2sMKDfC-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "out_channels = (5 + NUM_CLASSES) * F_PRIORS.size(1)\n",
        "net = Darknet(out_channels, layers=[1, 2, 2, 2, 1], f_channels=32)\n",
        "criterion = YOLOLoss(NUM_CLASSES, p=0.02)\n",
        "# optimizer = SGD(filter(lambda x: x.requires_grad, net.parameters()),\n",
        "#                 lr=1e-2, momentum=0.9, dampening=0.9, weight_decay=5e-4)\n",
        "optimizer = Adam(filter(lambda x: x.requires_grad,\n",
        "                        net.parameters()), lr=1e-3, weight_decay=1e-4)\n",
        "lr_scheduler = MultiStepLR(optimizer, [], gamma=0.1)\n",
        "\n",
        "\n",
        "metrics = {\n",
        "    'loss': TrainLoss(),\n",
        "}\n",
        "inference = YOLOInference(WIDTH, HEIGHT, F_PRIORS, topk=4)\n",
        "test_metrics = {\n",
        "    'mAP': MeanAveragePrecision(inference)\n",
        "}\n",
        "\n",
        "trainer = Trainer(net, criterion, optimizer, lr_scheduler,\n",
        "                  metrics=metrics, evaluate_metrics=test_metrics,\n",
        "                  save_path=gpath(\"models\"), name=\"YOLO-CAPTCHA\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9BS5LcVwYR-7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "summary(net, (3,HEIGHT, WIDTH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XLC97Lb7Ehjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    ds_train, batch_size=16, shuffle=True, num_workers=1, pin_memory=True)\n",
        "val_loader = DataLoader(\n",
        "    ds_val, batch_size=64, collate_fn=box_collate_fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8eLWKtgHjjC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer.fit(train_loader, 10, val_loader=val_loader, save_per_epochs=1)\n",
        "# trainer.fit(train_loader, 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UJfwzEmL9tCm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(trainer.metric_history['loss'][-20:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VuiEUeJ8Nm1y",
        "colab_type": "code",
        "outputId": "a5f6aa37-7a1a-40cc-e954-451e704970b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "%time trainer.evaluate(val_loader)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.14 s, sys: 208 ms, total: 1.35 s\n",
            "Wall time: 1.38 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mAP': 0.9085555555555556}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "mqHElNWAzkK_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}