{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SSD_VOC.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","id":"SG15RsvpbZVB","colab":{}},"cell_type":"code","source":["!pip3 uninstall pytorch-hrvvi-ext\n","!pip3 install -U --no-cache-dir --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple pytorch-hrvvi-ext"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1550367415905,"user_tz":-480,"elapsed":1319,"user":{"displayName":"沈碧螺","photoUrl":"","userId":"13913425030906926351"}},"id":"hYoZ6GBgbagm","outputId":"26cd5a9d-a4ae-40fc-8a20-deb5ab09acd0","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import sys\n","import os\n","\n","import torch\n","import hutil\n","import matplotlib.pyplot as plt\n","print(hutil.__version__)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["1.4.4\n"],"name":"stdout"}]},{"metadata":{"id":"fQPs47lgEFMw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"8af1304d-73ca-40bc-bb2d-eb2ecb31eee3","executionInfo":{"status":"ok","timestamp":1550367415915,"user_tz":-480,"elapsed":1099,"user":{"displayName":"沈碧螺","photoUrl":"","userId":"13913425030906926351"}}},"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":13,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"YjUdIrJusmXI","outputId":"efa27c6c-23b2-429a-9e87-c59a4f6de9c2","executionInfo":{"status":"ok","timestamp":1550367423112,"user_tz":-480,"elapsed":7920,"user":{"displayName":"沈碧螺","photoUrl":"","userId":"13913425030906926351"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["gdrive = \"/gdrive\"\n","from google.colab import drive\n","drive.mount(gdrive, force_remount=True)\n","mydrive = os.path.join(gdrive, \"My Drive\")\n","!ls /gdrive/My\\ Drive\n","\n","def gpath(p):\n","    return os.path.join(mydrive, p)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n","'Colab Notebooks'   eng-fra.pt\t images   repo\t   weixin.pkl\n"," datasets\t    fonts\t models   result\n"],"name":"stdout"}]},{"metadata":{"id":"nj37eIuqn3Mt","colab_type":"code","colab":{}},"cell_type":"code","source":["import random\n","\n","from PIL import Image\n","from toolz import curry\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD\n","from torch.optim.lr_scheduler import LambdaLR, MultiStepLR\n","from torch.utils.data import DataLoader\n","\n","from torch.utils.data.dataloader import default_collate\n","\n","from hutil import cuda\n","from hutil.datasets import VOCDetection\n","from hutil.data import train_test_split, Fullset\n","from hutil.train import init_weights, Trainer, Args\n","from hutil.train.metrics import TrainLoss, MeanAveragePrecision\n","from hutil.ext.summary import summary\n","from hutil.detection import BoundingBox, BoundingBoxFormat, transform_bbox, transform_bboxes, iou_1m\n","from hutil.transformers import Compose, Resize, ToTensor, ToPercentCoords, CenterCrop"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"tuBNyhdMSp4d","colab":{}},"cell_type":"code","source":["def iou_1m_centers(box, boxes):\n","    box = transform_bboxes(\n","        box, format=BoundingBoxFormat.XYWH, to=BoundingBoxFormat.LTRB)\n","    boxes = transform_bboxes(\n","        boxes, format=BoundingBoxFormat.XYWH, to=BoundingBoxFormat.LTRB)\n","    return iou_1m(box, boxes)\n","\n","def non_max_suppression(boxes, confidences, max_boxes, iou_threshold, inplace=False):\n","    r\"\"\"\n","    Args:\n","        boxes:       (N, 4)\n","        confidences: (N,)\n","        max_boxes (int): \n","        iou_threshold (float):\n","    Returns:\n","        indices: (N,)\n","    \"\"\"\n","    if len(boxes) == 0:\n","        return []\n","    if not inplace:\n","        boxes = boxes.clone()\n","        confidences = confidences.clone()\n","    boxes = boxes.view(-1, 4)\n","    confidences = confidences.view(-1)\n","    indices = []\n","    while True:\n","        ind = confidences.argmax()\n","        indices.append(ind.item())\n","        boxes_iou = iou_1m(boxes[ind], boxes)\n","        mask = boxes_iou > iou_threshold\n","        boxes.masked_fill_(mask.unsqueeze(-1), 0)\n","        confidences.masked_fill_(mask, 0)\n","        if len(indices) >= max_boxes or confidences.sum() == 0:\n","            return indices\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h8MEcOIOl4Q9","colab_type":"code","colab":{}},"cell_type":"code","source":["def compute_default_boxes(lx, ly, scale, ars):\n","    default_boxes = torch.zeros(lx, ly, len(ars), 4)\n","    default_boxes[:, :, :, 0] = (torch.arange(\n","        lx, dtype=torch.float).view(lx, 1, 1).expand(lx, ly, len(ars)) + 0.5) / lx\n","    default_boxes[:, :, :, 1] = (torch.arange(\n","        ly, dtype=torch.float).view(1, ly, 1).expand(lx, ly, len(ars)) + 0.5) / ly\n","    default_boxes[:, :, :, 2] = scale * torch.sqrt(ars)\n","    default_boxes[:, :, :, 3] = scale / torch.sqrt(ars)\n","    return default_boxes\n","\n","\n","def compute_scales(num_feature_maps, s_min, s_max):\n","    return [\n","        s_min + (s_max - s_min) * k / (num_feature_maps - 1)\n","        for k in range(num_feature_maps)\n","    ]\n","\n","\n","def compute_loc_target(gt_box, default_boxes):\n","    box_txty = (gt_box[:2] - default_boxes[..., :2]) \\\n","        / default_boxes[..., 2:]\n","    box_twth = torch.log(gt_box[2:] / default_boxes[..., 2:])\n","    return torch.cat((box_txty, box_twth), dim=-1)\n","\n","\n","class SSDTransform:\n","\n","    def __init__(self, scales, default_boxes, num_classes, label_field=\"category_id\", bbox_field=\"bbox\"):\n","        self.f_scales = scales\n","        self.f_default_boxes = default_boxes\n","        self.num_classes = num_classes\n","        self.label_field = label_field\n","        self.bbox_field = bbox_field\n","\n","    def __call__(self, img, anns):\n","        f_default_boxes = self.f_default_boxes\n","        f_classes = []\n","        f_boxes = []\n","        for d_boxes in self.f_default_boxes:\n","            shape = d_boxes.shape[:3]\n","            f_classes.append(torch.full(\n","                shape, self.num_classes - 1, dtype=torch.long))\n","            f_boxes.append(torch.zeros(*shape, 4))\n","        for ann in anns:\n","            label = ann[self.label_field]\n","            x, y, w, h = ann[self.bbox_field]\n","            cx = x + w / 2\n","            cy = y + h / 2\n","            bbox = torch.tensor([cx, cy, w, h])\n","\n","            max_ious = []\n","            for default_boxes, classes, boxes in zip(f_default_boxes, f_classes, f_boxes):\n","                lx, ly = default_boxes.shape[:2]\n","                xi = int(cx * lx)\n","                yi = int(cy * ly)\n","\n","                ious = iou_1m_centers(bbox, default_boxes)\n","\n","                iou_mask = ious > 0.5\n","                if ious[iou_mask].nelement() != 0:\n","                    classes[iou_mask] = label\n","                    boxes[iou_mask] = compute_loc_target(\n","                        bbox, default_boxes[iou_mask])\n","\n","                max_iou, max_i = ious.view(-1).max(dim=0)\n","                max_ious.append((max_iou, max_i))\n","\n","            f_i, (max_iou, max_i) = max(\n","                enumerate(max_ious), key=lambda t: t[1][0])\n","            f_classes[f_i].view(-1)[max_i] = label\n","            max_boxes = f_default_boxes[f_i].view(-1, 4)[max_i]\n","            f_boxes[f_i].view(-1, 4)[max_i] = \\\n","                compute_loc_target(bbox, max_boxes)\n","        return img, [f_classes, f_boxes]\n","\n","\n","class SSDLoss(nn.Module):\n","    def __init__(self, num_classes, neg_pos_ratio=3):\n","        super().__init__()\n","        self.num_classes = num_classes\n","        self.neg_pos_ratio = neg_pos_ratio\n","\n","    def forward(self, fs, f_classes, f_boxes):\n","        total_loc_loss = 0\n","        total_conf_loss_neg = 0\n","        total_conf_loss_pos = 0\n","        loss = 0\n","        total_pos = 0\n","        for f, classes, boxes in zip(fs, f_classes, f_boxes):\n","            n_ars = boxes.size(3)\n","            f = f.view(*f.size()[:3], n_ars, -1)\n","            loc_pred = f[..., :4]\n","            logits_pred = f[..., 4:]\n","            BACKGROUND_CLASS = self.num_classes - 1\n","            pos = classes != BACKGROUND_CLASS\n","            num_pos = pos.sum().item()\n","            total_pos += num_pos\n","            if num_pos == 0:\n","                continue\n","            conf_loss_pos = F.cross_entropy(\n","                logits_pred[pos], classes[pos], reduction='sum')\n","\n","            conf_loss_neg = -F.log_softmax(\n","                logits_pred[~pos], dim=1)[..., BACKGROUND_CLASS]\n","            num_neg = min(self.neg_pos_ratio * num_pos, len(conf_loss_neg))\n","            if num_neg != 0:\n","                conf_loss_neg = torch.topk(\n","                    conf_loss_neg, num_neg, sorted=False)[0].sum()\n","            else:\n","                conf_loss_neg = torch.zeros_like(conf_loss_pos)\n","            loc_loss = F.smooth_l1_loss(\n","                loc_pred[pos], boxes[pos], reduction='sum')\n","            total_loc_loss += loc_loss\n","            total_conf_loss_pos += conf_loss_pos\n","            total_conf_loss_neg += conf_loss_neg\n","        if random.random() < 0.01:\n","            print(\"loc: %.4f  conf_neg: %.4f conf_pos: %.4f\" %\n","                  (total_loc_loss.item() / total_pos,\n","                   total_conf_loss_neg.item() / total_pos,\n","                   total_conf_loss_pos.item() / total_pos))\n","        loss = (total_loc_loss + total_conf_loss_neg +\n","                total_conf_loss_pos) / total_pos\n","        return loss\n","\n","\n","class SSDInference:\n","\n","    def __init__(self, width, height, f_default_boxes, num_classes, confidence_threshold=0.01, max_boxes=10, iou_threshold=0.45):\n","        self.width = width\n","        self.height = height\n","        self.f_default_boxes = f_default_boxes\n","        self.confidence_threshold = confidence_threshold\n","        self.max_boxes = max_boxes\n","        self.iou_threshold = iou_threshold\n","        self.num_classes = num_classes\n","\n","    def __call__(self, fs):\n","        detections = []\n","        for f, default_boxes in zip(fs, self.f_default_boxes):\n","            batch_size = f.size(0)\n","            lx, ly, num_ars = default_boxes.size()[:3]\n","            f = f.view(batch_size, lx, ly, num_ars, -1)\n","            boxes_txty = f[..., 0:2]\n","            boxes_twth = f[..., 2:4]\n","            logits = f[..., 4:]\n","\n","            boxes_cxcy = boxes_txty.mul_(\n","                default_boxes[..., 2:]).add_(default_boxes[..., :2])\n","            boxes_wh = boxes_twth.exp_().mul_(default_boxes[..., 2:])\n","            boxes = f[..., :4]  # inplace\n","            boxes[..., [0, 2]] *= self.width\n","            boxes[..., [1, 3]] *= self.height\n","            boxes = transform_bboxes(\n","                boxes, format=BoundingBoxFormat.XYWH, to=BoundingBoxFormat.LTRB, inplace=True)\n","            confidences = torch.softmax(logits, dim=-1)\n","            # confidences, classes = torch.softmax(logits, dim=-1).max(dim=-1)\n","\n","            mask = confidences > self.confidence_threshold\n","            # confidences = confidences[mask]\n","            # classes =\n","\n","            for i in range(batch_size):\n","                for c in range(self.num_classes - 1):\n","                    bc_mask = mask[i, ..., c]\n","                    bc_confidences = confidences[i, ..., c][bc_mask]\n","                    bc_boxes = boxes[i][bc_mask]\n","                    indices = non_max_suppression(\n","                        bc_boxes, bc_confidences, self.max_boxes, self.iou_threshold)\n","                    for ind in indices:\n","                        detections.append(\n","                            BoundingBox(\n","                                image_name=i,\n","                                class_id=c,\n","                                box=bc_boxes[ind].tolist(),\n","                                confidence=bc_confidences[ind].item(),\n","                                box_format=BoundingBoxFormat.LTRB,\n","                            )\n","                        )\n","        return detections\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f9jBuBw5ESdz","colab_type":"code","colab":{}},"cell_type":"code","source":["class SELayer(nn.Module):\n","    def __init__(self, in_channels, reduction=8):\n","        super().__init__()\n","        channels = in_channels // reduction\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\n","        self.layers = nn.Sequential(\n","            nn.Linear(in_channels, channels),\n","            nn.ReLU(True),\n","            nn.Linear(channels, in_channels),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        b, c = x.size()[:2]\n","        s = self.avgpool(x).view(b, c)\n","        s = self.layers(s).view(b, c, 1, 1)\n","        return x * s\n","\n","\n","class PredTransition(nn.Module):\n","    def __init__(self, in_channels, out_channels, last=False):\n","        super().__init__()\n","        self.bn1 = nn.BatchNorm2d(in_channels)\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_channels, out_channels // 2, kernel_size=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels // 2)\n","        self.relu2 = nn.ReLU(inplace=True)\n","        if last:\n","            self.conv2 = nn.Conv2d(out_channels // 2, out_channels,\n","                                   kernel_size=3)\n","        else:\n","            self.conv2 = nn.Conv2d(out_channels // 2, out_channels,\n","                                   kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","        x = self.conv1(x)\n","        x = self.bn2(x)\n","        x = self.relu2(x)\n","        x = self.conv2(x)\n","        return x\n","\n","\n","class Bottleneck(nn.Module):\n","    def __init__(self, in_channels, growth_rate, with_se=False):\n","        super().__init__()\n","        self.bn1 = nn.BatchNorm2d(in_channels)\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1)\n","        self.bn2 = nn.BatchNorm2d(4 * growth_rate)\n","        self.relu2 = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(4 * growth_rate, growth_rate,\n","                               kernel_size=3, stride=1, padding=1)\n","        self.se = None\n","        if with_se:\n","            self.se = SELayer(growth_rate)\n","\n","    def forward(self, x):\n","        residual = x\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","        x = self.conv1(x)\n","        x = self.bn2(x)\n","        x = self.relu2(x)\n","        x = self.conv2(x)\n","\n","        if self.se:\n","            x = self.se(x)\n","        return torch.cat((residual, x), dim=1)\n","\n","\n","class DenseBlock(nn.Module):\n","    def __init__(self, in_channels, growth_rate, n, with_se=False):\n","        super().__init__()\n","        layers = []\n","        channels = in_channels\n","        for i in range(n):\n","            layers.append(Bottleneck(channels, growth_rate, with_se=with_se))\n","            channels += growth_rate\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        return x\n","\n","\n","class Transition(nn.Module):\n","    def __init__(self, in_channels, out_channels, with_pool=True):\n","        super().__init__()\n","        self.with_pool = with_pool\n","        self.bn = nn.BatchNorm2d(in_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        x = self.conv(x)\n","        if self.with_pool:\n","            x = F.max_pool2d(x, kernel_size=2, stride=2, ceil_mode=True)\n","        return x\n","\n","\n","class DSOD(nn.Module):\n","    stages = [6, 6, 6]\n","\n","    def __init__(self, layers, growth_rate, in_channels=3, out_channels=None, reduction=0.5, with_se=False):\n","        super().__init__()\n","        channels = 64\n","        self.stem = nn.Sequential(\n","            nn.Conv2d(in_channels, channels,\n","                      kernel_size=3, stride=2, padding=1),\n","            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n","            nn.Conv2d(channels, 2 * channels,\n","                      kernel_size=3, stride=1, padding=1),\n","            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n","        )\n","        channels = 2 * channels\n","        self.block1 = DenseBlock(\n","            channels, growth_rate, layers[0], with_se=with_se)\n","        channels += layers[0] * growth_rate\n","        self.transition1 = Transition(channels, int(channels * reduction))\n","        channels = int(channels * reduction)\n","\n","        self.block2 = DenseBlock(\n","            channels, growth_rate, layers[1], with_se=with_se)\n","        channels += layers[1] * growth_rate\n","        self.pred1 = nn.Linear(channels, out_channels[0])\n","        self.transition2 = Transition(channels, int(channels * reduction))\n","        channels = int(channels * reduction)\n","\n","        self.block3 = DenseBlock(\n","            channels, growth_rate, layers[2], with_se=with_se)\n","        channels += layers[2] * growth_rate\n","        self.transition3 = Transition(channels, int(\n","            channels * reduction), with_pool=False)\n","        channels = int(channels * reduction)\n","\n","        self.block4 = DenseBlock(\n","            channels, growth_rate, layers[3], with_se=with_se)\n","        channels += layers[3] * growth_rate\n","        self.transition4 = Transition(channels, int(\n","            channels * reduction), with_pool=False)\n","        channels = int(channels * reduction)\n","\n","        self.pred2 = nn.Linear(channels, out_channels[1])\n","        self.t1 = PredTransition(channels, 512)\n","        self.pred3 = nn.Linear(512, out_channels[2])\n","        self.t2 = PredTransition(512, 256)\n","        self.pred4 = nn.Linear(256, out_channels[3])\n","        self.t3 = PredTransition(256, 256)\n","        self.pred5 = nn.Linear(256, out_channels[4])\n","        self.t4 = PredTransition(256, 256, last=True)\n","        self.pred6 = nn.Linear(256, out_channels[5])\n","\n","        # self.avgpool = nn.AdaptiveAvgPool2d(1)\n","        # self.fc = nn.Linear(channels, out_channels)\n","\n","    def forward(self, x):\n","        x = self.stem(x)\n","\n","        x = self.block1(x)\n","        x = self.transition1(x)\n","\n","        x = self.block2(x)\n","        f1 = self.pred1(x.permute(0, 3, 2, 1).contiguous())\n","        x = self.transition2(x)\n","\n","        x = self.block3(x)\n","        x = self.transition3(x)\n","\n","        x = self.block4(x)\n","        x = self.transition4(x)\n","\n","        f2 = self.pred2(x.permute(0, 3, 2, 1).contiguous())\n","        x = self.t1(x)\n","        f3 = self.pred3(x.permute(0, 3, 2, 1).contiguous())\n","        x = self.t2(x)\n","        f4 = self.pred4(x.permute(0, 3, 2, 1).contiguous())\n","        x = self.t3(x)\n","        f5 = self.pred5(x.permute(0, 3, 2, 1).contiguous())\n","        x = self.t4(x)\n","        f6 = self.pred6(x.permute(0, 3, 2, 1).contiguous())\n","\n","        # x = self.avgpool(x)\n","        # x = x.view(x.size(0), -1)\n","        # x = self.fc(x)\n","        return [[f1, f2, f3, f4, f5, f6]]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xNpK9h-iLMQ2","colab_type":"code","colab":{}},"cell_type":"code","source":["def val_collate_fn(batch):\n","    x, y = zip(*batch)\n","    ground_truths = []\n","    for i in range(len(y)):\n","        for ann in y[i]:\n","            ground_truths.append(\n","                BoundingBox(\n","                    image_name=i,\n","                    class_id=ann[\"category_id\"],\n","                    box=ann[\"bbox\"],\n","                    box_format=BoundingBoxFormat.LTWH,\n","                )\n","            )\n","    return default_collate(x), Args(ground_truths)\n","\n","\n","WIDTH = 300\n","HEIGHT = 300\n","LOCATIONS = [\n","    (38, 38),\n","    (19, 19),\n","    (10, 10),\n","    (5, 5),\n","    (3, 3),\n","    (1, 1),\n","]\n","ASPECT_RATIOS = [\n","    (1, 2, 1/2),\n","    (1, 2, 3, 1/2, 1/3),\n","    (1, 2, 3, 1/2, 1/3),\n","    (1, 2, 3, 1/2, 1/3),\n","    (1, 2, 3, 1/2, 1/3),\n","    (1, 2, 1/2),\n","]\n","ASPECT_RATIOS = [torch.tensor(ars) for ars in ASPECT_RATIOS]\n","NUM_FEATURE_MAPS = len(ASPECT_RATIOS)\n","SCALES = compute_scales(NUM_FEATURE_MAPS, 0.2, 0.9)\n","DEFAULT_BOXES = [\n","    compute_default_boxes(lx, ly, scale, ars)\n","    for (lx, ly), scale, ars in zip(LOCATIONS, SCALES, ASPECT_RATIOS)\n","]\n","\n","NUM_CLASSES = 21 + 1\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cj2oL90kEdRV","colab_type":"code","outputId":"ea20a2a6-4f9a-4ae8-8dcd-388225c7574a","executionInfo":{"status":"ok","timestamp":1550370503041,"user_tz":-480,"elapsed":1264,"user":{"displayName":"沈碧螺","photoUrl":"","userId":"13913425030906926351"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["\n","train_transform = Compose([\n","    Resize(HEIGHT),\n","    CenterCrop(HEIGHT),\n","    ToPercentCoords(),\n","    ToTensor(),\n","    SSDTransform(SCALES, DEFAULT_BOXES, NUM_CLASSES),\n","])\n","\n","test_transform = Compose([\n","    Resize(HEIGHT),\n","    CenterCrop(HEIGHT),\n","    ToTensor(),\n","])\n","\n","data_home = \"./VOC\"\n","ds = VOCDetection(data_home, year='2012', image_set='trainval', download=True)\n","ds_train, ds_val = train_test_split(\n","    ds, test_ratio=0.05,\n","    transform=train_transform,\n","    test_transform=test_transform)\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Dataset found. Skip download or extract\n"],"name":"stdout"}]},{"metadata":{"id":"UmHY45pBR_Wn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"69c8a3d6-a8d9-4a0f-f631-18601ad2eb6d","executionInfo":{"status":"ok","timestamp":1550370480840,"user_tz":-480,"elapsed":1181,"user":{"displayName":"沈碧螺","photoUrl":"","userId":"13913425030906926351"}}},"cell_type":"code","source":["len(ds_val)"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1154"]},"metadata":{"tags":[]},"execution_count":28}]},{"metadata":{"id":"aRhNUTev-_EP","colab_type":"code","colab":{}},"cell_type":"code","source":["out_channels = [\n","    (NUM_CLASSES + 4) * len(ars)\n","    for ars in ASPECT_RATIOS\n","]\n","net = DSOD([3, 4, 4, 4], 36, out_channels=out_channels, reduction=1)\n","net.apply(init_weights(nonlinearity='relu'))\n","criterion = SSDLoss(NUM_CLASSES)\n","optimizer = Adam(net.parameters(), lr=3e-4, weight_decay=1e-4)\n","lr_scheduler = MultiStepLR(optimizer, [60, 90, 120], gamma=0.2)\n","# lr_scheduler = LambdaLR(optimizer, lambda x: 0.96 ** x)\n","\n","\n","metrics = {\n","    'loss': TrainLoss(),\n","}\n","test_metrics = {\n","    'mAP': MeanAveragePrecision(\n","        SSDInference(\n","            width=WIDTH, height=HEIGHT,\n","            f_default_boxes=[ cuda(d) for d in DEFAULT_BOXES ],\n","            num_classes=NUM_CLASSES,\n","        )\n","    )\n","}\n","\n","trainer = Trainer(net, criterion, optimizer, lr_scheduler,\n","                  metrics=metrics, evaluate_metrics=test_metrics,\n","                  save_path=gpath(\"models\"), name=\"DSOD-VOC\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YIE_X-US_19i","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = SSDLoss(NUM_CLASSES)\n","trainer.criterion = criterion"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0KW02nJcKif6","colab_type":"code","colab":{}},"cell_type":"code","source":["summary(net, (3,HEIGHT, WIDTH))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XLC97Lb7Ehjt","colab_type":"code","colab":{}},"cell_type":"code","source":["train_loader = DataLoader(\n","    ds_train, batch_size=32, shuffle=True, num_workers=1, pin_memory=True)\n","val_loader = DataLoader(\n","    ds_val, batch_size=128, collate_fn=val_collate_fn)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q8eLWKtgHjjC","colab_type":"code","outputId":"c3f26b47-85bd-4dcf-b0c3-c2ad9c2c8b84","executionInfo":{"status":"error","timestamp":1550366910356,"user_tz":-480,"elapsed":1186,"user":{"displayName":"沈碧螺","photoUrl":"","userId":"13913425030906926351"}},"colab":{"base_uri":"https://localhost:8080/","height":544}},"cell_type":"code","source":["trainer.fit(train_loader, 10)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 19/28\n","loc: 0.0887  conf_neg: 0.8964 conf_pos: 2.1827\n","loc: 0.1007  conf_neg: 0.8661 conf_pos: 2.4947\n","elapsed: 419s\tloss: 3.3947\t\n","Epoch 20/28\n","loc: 0.0711  conf_neg: 0.8651 conf_pos: 2.6048\n","loc: 0.1260  conf_neg: 0.8596 conf_pos: 2.6511\n","loc: 0.0847  conf_neg: 0.8163 conf_pos: 2.3208\n","loc: 0.0872  conf_neg: 0.9124 conf_pos: 2.1116\n","elapsed: 415s\tloss: 3.3331\t\n","Epoch 21/28\n","loc: 0.0905  conf_neg: 0.8651 conf_pos: 2.2004\n","loc: 0.0799  conf_neg: 0.9225 conf_pos: 2.3447\n","loc: 0.0738  conf_neg: 0.9398 conf_pos: 1.9105\n","elapsed: 415s\tloss: 3.2677\t\n","Epoch 22/28\n","elapsed: 417s\tloss: 3.2074\t\n","Epoch 23/28\n","elapsed: 414s\tloss: 3.1730\t\n","Epoch 24/28\n","loc: 0.0811  conf_neg: 0.8849 conf_pos: 2.3790\n","loc: 0.0714  conf_neg: 0.7933 conf_pos: 2.2258\n","loc: 0.0793  conf_neg: 0.8140 conf_pos: 2.2804\n","loc: 0.0692  conf_neg: 0.9004 conf_pos: 1.9998\n","elapsed: 415s\tloss: 3.1068\t\n","Epoch 25/28\n","loc: 0.0761  conf_neg: 0.7755 conf_pos: 2.1142\n","loc: 0.0805  conf_neg: 0.8564 conf_pos: 2.2838\n","loc: 0.1051  conf_neg: 0.8636 conf_pos: 2.4166\n","elapsed: 416s\tloss: 3.0537\t\n","Epoch 26/28\n"],"name":"stdout"}]},{"metadata":{"id":"4nhAkuJcIS7i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"7a4e34f7-3067-4e43-b432-99f2f45f7a5b","executionInfo":{"status":"ok","timestamp":1550385441209,"user_tz":-480,"elapsed":646123,"user":{"displayName":"沈碧螺","photoUrl":"","userId":"13913425030906926351"}}},"cell_type":"code","source":["%time trainer.evaluate(val_loader)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["CPU times: user 7min 17s, sys: 1min 14s, total: 8min 32s\n","Wall time: 10min 44s\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'mAP': 0.16537328396609896}"]},"metadata":{"tags":[]},"execution_count":38}]},{"metadata":{"id":"_3_1NgNFInR0","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}