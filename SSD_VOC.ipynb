{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSD_VOC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "SG15RsvpbZVB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 uninstall pytorch-hrvvi-ext -y\n",
        "!pip3 install -U --no-cache-dir pytorch-hrvvi-ext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hYoZ6GBgbagm",
        "outputId": "e65701ea-f9b7-459f-83a9-8096d58e3211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import hutil\n",
        "import matplotlib.pyplot as plt\n",
        "print(hutil.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fQPs47lgEFMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YjUdIrJusmXI",
        "outputId": "36147a16-4fea-4192-8371-1951bae98b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "gdrive = \"/gdrive\"\n",
        "from google.colab import drive\n",
        "drive.mount(gdrive, force_remount=True)\n",
        "mydrive = os.path.join(gdrive, \"My Drive\")\n",
        "!ls /gdrive/My\\ Drive\n",
        "\n",
        "def gpath(p):\n",
        "    return os.path.join(mydrive, p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "'Colab Notebooks'   eng-fra.pt\t images   repo\t   weixin.pkl\n",
            " datasets\t    fonts\t models   result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nj37eIuqn3Mt",
        "colab_type": "code",
        "outputId": "1d90e7a2-d655-4ea6-d5d1-4af2ad0fc032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from toolz import curry\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import LambdaLR, MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "from hutil import cuda\n",
        "from hutil.datasets import VOCDetection\n",
        "from hutil.data import train_test_split, Fullset\n",
        "from hutil.train import init_weights, Trainer\n",
        "from hutil.train.metrics import TrainLoss, MeanAveragePrecision\n",
        "from hutil.ext.summary import summary\n",
        "from hutil.detection import BoundingBox, transform_bbox, transform_bboxes, iou_1m, non_max_suppression, box_collate_fn\n",
        "from hutil.transforms import Compose, Resize, ToTensor, ToPercentCoords, CenterCrop\n",
        "from hutil.inference import freeze\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tuBNyhdMSp4d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def iou_1m_centers(box, boxes):\n",
        "    box = transform_bboxes(\n",
        "        box, format=BoundingBox.XYWH, to=BoundingBox.LTRB)\n",
        "    boxes = transform_bboxes(\n",
        "        boxes, format=BoundingBox.XYWH, to=BoundingBox.LTRB)\n",
        "    return iou_1m(box, boxes)\n",
        "\n",
        "\n",
        "def compute_default_boxes(lx, ly, scale, ars):\n",
        "    default_boxes = torch.zeros(lx, ly, len(ars), 4)\n",
        "    default_boxes[:, :, :, 0] = (torch.arange(\n",
        "        lx, dtype=torch.float).view(lx, 1, 1).expand(lx, ly, len(ars)) + 0.5) / lx\n",
        "    default_boxes[:, :, :, 1] = (torch.arange(\n",
        "        ly, dtype=torch.float).view(1, ly, 1).expand(lx, ly, len(ars)) + 0.5) / ly\n",
        "    default_boxes[:, :, :, 2] = scale * torch.sqrt(ars)\n",
        "    default_boxes[:, :, :, 3] = scale / torch.sqrt(ars)\n",
        "    return default_boxes\n",
        "\n",
        "\n",
        "def compute_scales(num_feature_maps, s_min, s_max):\n",
        "    return [\n",
        "        s_min + (s_max - s_min) * k / (num_feature_maps - 1)\n",
        "        for k in range(num_feature_maps)\n",
        "    ]\n",
        "\n",
        "\n",
        "def compute_loc_target(gt_box, default_boxes):\n",
        "    box_txty = (gt_box[:2] - default_boxes[..., :2]) \\\n",
        "        / default_boxes[..., 2:]\n",
        "    box_twth = torch.log(gt_box[2:] / default_boxes[..., 2:])\n",
        "    return torch.cat((box_txty, box_twth), dim=-1)\n",
        "\n",
        "\n",
        "class SSDTransform:\n",
        "\n",
        "    def __init__(self, default_boxes, num_classes, label_field=\"category_id\", bbox_field=\"bbox\"):\n",
        "        self.default_boxes = default_boxes\n",
        "        self.num_classes = num_classes\n",
        "        self.label_field = label_field\n",
        "        self.bbox_field = bbox_field\n",
        "\n",
        "    def __call__(self, img, anns):\n",
        "        num_feature_maps = len(self.default_boxes)\n",
        "        loc_target = []\n",
        "        cls_target = []\n",
        "        default_boxes = []\n",
        "        for i in range(num_feature_maps):\n",
        "            d_boxes = self.default_boxes[i].view(-1, 4)\n",
        "            default_boxes.append(d_boxes)\n",
        "            num_anchors = d_boxes.size(0)\n",
        "            loc_target.append(torch.zeros(\n",
        "                num_anchors, 4))\n",
        "            cls_target.append(torch.full(\n",
        "                (num_anchors,), self.num_classes - 1, dtype=torch.long))\n",
        "\n",
        "        for ann in anns:\n",
        "            label = ann[self.label_field]\n",
        "            bbox = torch.tensor(\n",
        "                transform_bbox(\n",
        "                    ann[self.bbox_field],\n",
        "                    BoundingBox.LTWH,\n",
        "                    BoundingBox.XYWH))\n",
        "\n",
        "            max_ious = []\n",
        "            for d_boxes, cls_t, loc_t in zip(default_boxes, cls_target, loc_target):\n",
        "                ious = iou_1m_centers(bbox, d_boxes)\n",
        "                max_ious.append(ious.max(dim=0))\n",
        "\n",
        "                iou_mask = ious > 0.5\n",
        "                if iou_mask.sum() != 0:\n",
        "                    cls_t[iou_mask] = label\n",
        "                    loc_t[iou_mask] = compute_loc_target(\n",
        "                        bbox, d_boxes[iou_mask])\n",
        "\n",
        "            i, (max_iou, ind) = max(\n",
        "                enumerate(max_ious), key=lambda x: x[1][0])\n",
        "            loc_target[i][ind] = compute_loc_target(\n",
        "                bbox, default_boxes[i][ind])\n",
        "            cls_target[i][ind] = label\n",
        "        return img, [loc_target, cls_target]\n",
        "\n",
        "\n",
        "class SSDLoss(nn.Module):\n",
        "    def __init__(self, num_classes, neg_pos_ratio=3, p=0.01):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.neg_pos_ratio = neg_pos_ratio\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, loc_preds, cls_preds, loc_target, cls_target):\n",
        "        BACKGROUND_CLASS = self.num_classes - 1\n",
        "        total_pos = 0\n",
        "        loc_loss = 0\n",
        "        cls_loss_pos = 0\n",
        "        cls_loss_neg = 0\n",
        "        for loc_p, cls_p, loc_t, cls_t in zip(loc_preds, cls_preds, loc_target, cls_target):\n",
        "\n",
        "            pos = cls_t != BACKGROUND_CLASS\n",
        "            num_pos = pos.sum().item()\n",
        "            if num_pos == 0:\n",
        "                continue\n",
        "\n",
        "            total_pos += num_pos\n",
        "\n",
        "            cls_loss_pos += F.cross_entropy(\n",
        "                cls_p[pos], cls_t[pos], reduction='sum')\n",
        "\n",
        "            cls_loss_neg_all = -F.log_softmax(\n",
        "                cls_p[~pos], dim=1)[..., BACKGROUND_CLASS]\n",
        "            num_neg = min(self.neg_pos_ratio * num_pos, len(cls_loss_neg_all))\n",
        "            if num_neg != 0:\n",
        "                cls_loss_neg += torch.topk(\n",
        "                    cls_loss_neg_all, num_neg, sorted=False)[0].sum()\n",
        "            else:\n",
        "                cls_loss_neg += torch.zeros_like(cls_loss_pos)\n",
        "\n",
        "            loc_loss += F.smooth_l1_loss(\n",
        "                loc_p[pos], loc_t[pos], reduction='sum')\n",
        "\n",
        "        if random.random() < self.p:\n",
        "            print(\"loc: %.4f  cls_pos: %.4f cls_neg: %.4f\" %\n",
        "                  (loc_loss.item() / total_pos,\n",
        "                   cls_loss_pos.item() / total_pos,\n",
        "                   cls_loss_neg.item() / total_pos))\n",
        "\n",
        "        loss = (loc_loss + cls_loss_pos + cls_loss_neg) / total_pos\n",
        "        return loss\n",
        "\n",
        "\n",
        "class SSDInference:\n",
        "\n",
        "    def __init__(self, width, height, default_boxes, num_classes, conf_threshold=0.01, max_boxes=0, iou_threshold=0.45):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.default_boxes = default_boxes\n",
        "        self.num_classes = num_classes\n",
        "        self.conf_threshold = conf_threshold\n",
        "        self.max_boxes = max_boxes\n",
        "        self.iou_threshold = iou_threshold\n",
        "\n",
        "    def __call__(self, loc_preds, cls_preds):\n",
        "        detections = []\n",
        "        batch_size = cls_preds[0].size(0)\n",
        "        for i in range(batch_size):\n",
        "            boxes = []\n",
        "            confs = []\n",
        "            labels = []\n",
        "            for loc_p, cls_p, d_boxes in zip(loc_preds, cls_preds, self.default_boxes):\n",
        "                loc_p = loc_p[i]\n",
        "                cls_p = cls_p[i]\n",
        "                d_boxes = d_boxes.view(-1, 4)\n",
        "\n",
        "                conf = torch.softmax(cls_p, dim=1)[..., :-1]\n",
        "                conf, label = torch.max(conf, dim=1)\n",
        "\n",
        "                mask = conf > self.conf_threshold\n",
        "                conf = conf[mask]\n",
        "                label = label[mask]\n",
        "                box = loc_p[mask]\n",
        "                d_boxes = d_boxes[mask]\n",
        "\n",
        "                box[:, :2].mul_(d_boxes[:, 2:]).add_(d_boxes[:, :2])\n",
        "                box[:, 2:].exp_().mul_(d_boxes[:, 2:])\n",
        "                box[:, [0, 2]] *= self.width\n",
        "                box[:, [1, 3]] *= self.height\n",
        "\n",
        "                boxes.append(box)\n",
        "                confs.append(conf)\n",
        "                labels.append(label)\n",
        "\n",
        "            boxes = torch.cat(boxes, dim=0)\n",
        "            confs = torch.cat(confs, dim=0)\n",
        "            labels = torch.cat(labels, dim=0)\n",
        "\n",
        "            boxes = transform_bboxes(\n",
        "                boxes, format=BoundingBox.XYWH, to=BoundingBox.LTRB, inplace=True)\n",
        "            indices = non_max_suppression(\n",
        "                boxes, confs, self.max_boxes, self.iou_threshold)\n",
        "            dets = [\n",
        "                BoundingBox(\n",
        "                    image_name=i,\n",
        "                    class_id=labels[ind].item(),\n",
        "                    box=boxes[ind].tolist(),\n",
        "                    confidence=confs[ind].item(),\n",
        "                    box_format=BoundingBox.LTRB,\n",
        "                ) for ind in indices\n",
        "            ]\n",
        "            detections += dets\n",
        "        return detections\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9jBuBw5ESdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def conv1x1(in_channels, out_channels):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "\n",
        "def conv3x3(in_channels, out_channels, stride=1, padding=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding)\n",
        "\n",
        "\n",
        "class PredTransition(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv1x1(in_channels, out_channels)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_channels, out_channels, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SSD(nn.Module):\n",
        "    def __init__(self, backbone, out_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = backbone.conv1\n",
        "        self.bn1 = backbone.bn1\n",
        "        self.relu = backbone.relu\n",
        "        self.maxpool = backbone.maxpool\n",
        "\n",
        "        self.layer1 = backbone.layer1\n",
        "        self.layer2 = backbone.layer2\n",
        "        self.layer3 = backbone.layer3\n",
        "        self.layer4 = backbone.layer4\n",
        "\n",
        "        self.t1 = PredTransition(512, 512)\n",
        "        self.t2 = PredTransition(512, 256)\n",
        "        self.t3 = PredTransition(256, 256)\n",
        "\n",
        "        self.pred1 = conv1x1(128, out_channels[0])\n",
        "        self.pred2 = conv1x1(256, out_channels[1])\n",
        "        self.pred3 = conv1x1(512, out_channels[2])\n",
        "        self.pred4 = conv1x1(512, out_channels[3])\n",
        "        self.pred5 = conv1x1(256, out_channels[4])\n",
        "        self.pred6 = conv1x1(256, out_channels[5])\n",
        "\n",
        "    def forward(self, x):\n",
        "        b = x.size(0)\n",
        "        c1 = self.conv1(x)\n",
        "        c1 = self.bn1(c1)\n",
        "        c1 = self.relu(c1)\n",
        "        c2 = self.maxpool(c1)\n",
        "\n",
        "        c2 = self.layer1(c2)\n",
        "        c3 = self.layer2(c2)\n",
        "        c4 = self.layer3(c3)\n",
        "        c5 = self.layer4(c4)\n",
        "\n",
        "        c6 = self.t1(c5)\n",
        "        c7 = self.t2(c6)\n",
        "        c8 = self.t3(c7)\n",
        "\n",
        "        f3 = self.pred1(c3)\n",
        "        f4 = self.pred2(c4)\n",
        "        f5 = self.pred3(c5)\n",
        "        f6 = self.pred4(c6)\n",
        "        f7 = self.pred5(c7)\n",
        "        f8 = self.pred6(c8)\n",
        "\n",
        "        fs = [f3, f4, f5, f6, f7, f8]\n",
        "\n",
        "        loc_preds = []\n",
        "        cls_preds = []\n",
        "        for f in fs:\n",
        "            f = f.permute(0, 3, 2, 1).contiguous().view(\n",
        "                b, -1, 4 + self.num_classes)\n",
        "            loc_preds.append(f[..., :4])\n",
        "            cls_preds.append(f[..., 4:])\n",
        "        return loc_preds, cls_preds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xNpK9h-iLMQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "WIDTH = 300\n",
        "HEIGHT = 300\n",
        "LOCATIONS = [\n",
        "    (38, 38),\n",
        "    (19, 19),\n",
        "    (10, 10),\n",
        "    (5, 5),\n",
        "    (3, 3),\n",
        "    (2, 2),\n",
        "]\n",
        "ASPECT_RATIOS = [\n",
        "    (1, 2, 1/2),\n",
        "    (1, 2, 3, 1/2, 1/3),\n",
        "    (1, 2, 3, 1/2, 1/3),\n",
        "    (1, 2, 3, 1/2, 1/3),\n",
        "    (1, 2, 3, 1/2, 1/3),\n",
        "    (1, 2, 1/2),\n",
        "]\n",
        "ASPECT_RATIOS = [torch.tensor(ars) for ars in ASPECT_RATIOS]\n",
        "NUM_FEATURE_MAPS = len(ASPECT_RATIOS)\n",
        "SCALES = compute_scales(NUM_FEATURE_MAPS, 0.2, 0.9)\n",
        "DEFAULT_BOXES = [\n",
        "    compute_default_boxes(lx, ly, scale, ars)\n",
        "    for (lx, ly), scale, ars in zip(LOCATIONS, SCALES, ASPECT_RATIOS)\n",
        "]\n",
        "\n",
        "NUM_CLASSES = 21\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cj2oL90kEdRV",
        "colab_type": "code",
        "outputId": "1e12e130-f604-4da6-bc09-bbc7e19197ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_transform = Compose([\n",
        "    Resize(HEIGHT),\n",
        "    CenterCrop(HEIGHT),\n",
        "    ToPercentCoords(),\n",
        "    ToTensor(),\n",
        "    SSDTransform(DEFAULT_BOXES, NUM_CLASSES),\n",
        "])\n",
        "\n",
        "test_transform = Compose([\n",
        "    Resize(HEIGHT),\n",
        "    CenterCrop(HEIGHT),\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "data_home = \"./VOC\"\n",
        "ds = VOCDetection(data_home, year='2012', image_set='trainval', download=True)\n",
        "rest, ds = train_test_split(ds, 0.003)\n",
        "ds_train = Fullset(ds, train_transform)\n",
        "ds_val = Fullset(ds, test_transform)\n",
        "# ds_train, ds_val = train_test_split(\n",
        "#     ds, test_ratio=0.05,\n",
        "#     transform=train_transform,\n",
        "#     test_transform=test_transform)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset found. Skip download or extract\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aRhNUTev-_EP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "backbone = resnet18(pretrained=True)\n",
        "del backbone.fc\n",
        "freeze(backbone)\n",
        "\n",
        "out_channels = [\n",
        "    (4 + NUM_CLASSES) * len(ars)\n",
        "    for ars in ASPECT_RATIOS\n",
        "]\n",
        "net = SSD(backbone, out_channels, NUM_CLASSES)\n",
        "# net.apply(init_weights(nonlinearity='relu'))\n",
        "criterion = SSDLoss(NUM_CLASSES, p=1)\n",
        "# optimizer = SGD(filter(lambda x: x.requires_grad, net.parameters()),\n",
        "#                 lr=1e-2, momentum=0.9, dampening=0.9, weight_decay=5e-4)\n",
        "optimizer = Adam(filter(lambda x: x.requires_grad,\n",
        "                        net.parameters()), lr=1e-2, weight_decay=5e-4, amsgrad=True)\n",
        "lr_scheduler = MultiStepLR(optimizer, [], gamma=0.1)\n",
        "# lr_scheduler = LambdaLR(optimizer, lambda x: 0.99 ** x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRyQRkECw1A3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "metrics = {\n",
        "    'loss': TrainLoss(),\n",
        "}\n",
        "inference = SSDInference(\n",
        "    WIDTH, HEIGHT, cuda(DEFAULT_BOXES), NUM_CLASSES, max_boxes=10,\n",
        ")\n",
        "test_metrics = {\n",
        "    'mAP': MeanAveragePrecision(inference)\n",
        "}\n",
        "\n",
        "\n",
        "trainer = Trainer(net, criterion, optimizer, lr_scheduler,\n",
        "                  metrics=metrics, evaluate_metrics=test_metrics,\n",
        "                  save_path=\"./checkpoints\", name=\"SSD-VOC\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KW02nJcKif6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "summary(net, (3,HEIGHT, WIDTH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XLC97Lb7Ehjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    ds_train, batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
        "val_loader = DataLoader(\n",
        "    ds_val, batch_size=64, collate_fn=box_collate_fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FfQxTTB9065J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hist = trainer.fit(train_loader, 20)\n",
        "plot_history(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nhAkuJcIS7i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_metrics['mAP'].predict.max_boxes = 100\n",
        "%time trainer.evaluate(val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_3_1NgNFInR0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}