{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RefineDet_VOC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3SrkiQNjxQCn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 uninstall pytorch-hrvvi-ext -y\n",
        "!pip3 install -U git+https://github.com/sbl1996/pytorch-hrvvi-ext.git\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hYoZ6GBgbagm",
        "outputId": "c8beea48-2d68-4a7a-afb6-1b799ffd4bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import hutil\n",
        "import matplotlib.pyplot as plt\n",
        "print(hutil.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fQPs47lgEFMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YjUdIrJusmXI",
        "outputId": "0b7e1711-1830-4fd6-822c-424cf6763a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "gdrive = \"/gdrive\"\n",
        "from google.colab import drive\n",
        "drive.mount(gdrive, force_remount=True)\n",
        "mydrive = os.path.join(gdrive, \"My Drive\")\n",
        "!ls /gdrive/My\\ Drive\n",
        "\n",
        "def gpath(p):\n",
        "    return os.path.join(mydrive, p)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "'Colab Notebooks'   eng-fra.pt\t images   repo\t   weixin.pkl\n",
            " datasets\t    fonts\t models   result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nj37eIuqn3Mt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9a436941-e588-462e-80cf-5e215701396a"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from toolz import curry\n",
        "from toolz.curried import get\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import LambdaLR, MultiStepLR\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "from torchvision.models.resnet import resnet50, Bottleneck\n",
        "\n",
        "from hutil import cuda, one_hot\n",
        "from hutil.data import train_test_split, Fullset\n",
        "from hutil.train import init_weights, Trainer\n",
        "from hutil.datasets.voc import VOCDetection, DETECTION_CATEGORIES\n",
        "from hutil.train.metrics import TrainLoss, MeanAveragePrecision\n",
        "from hutil.ext.summary import summary\n",
        "from hutil.detection import transform_bbox, box_collate_fn, draw_bboxes, BBox, non_max_suppression, iou_1m, transform_bboxes\n",
        "from hutil.transforms import UseOrigin, Compose, RandomChoice\n",
        "from hutil.transforms.detection import ToTensor, ToPercentCoords, RandomHorizontalFlip, RandomResizedCrop, Resize, CenterCrop\n",
        "from hutil.inference import freeze\n",
        "from hutil.model.utils import get_out_channels\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "â–ˆ\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tuBNyhdMSp4d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def inverse_sigmoid(x):\n",
        "    return math.log(x / (1-x))\n",
        "\n",
        "\n",
        "def get_whs(scales, aspect_ratios):\n",
        "    whs = torch.zeros(len(aspect_ratios), 2)\n",
        "    whs[:, 0] = aspect_ratios.sqrt() * scales[0]\n",
        "    whs[:, 1] = (1 / aspect_ratios.sqrt()) * scales[1]\n",
        "    return whs.view(-1, 2)\n",
        "\n",
        "\n",
        "def get_anchors(lx, ly, whs, width, height):\n",
        "    anchors = torch.zeros(lx, ly, len(whs), 4)\n",
        "    anchors[:, :, :, 0] = (torch.arange(\n",
        "        lx, dtype=torch.float).view(lx, 1, 1).expand(lx, ly, len(whs)) + 0.5) / lx\n",
        "    anchors[:, :, :, 1] = (torch.arange(\n",
        "        ly, dtype=torch.float).view(1, ly, 1).expand(lx, ly, len(whs)) + 0.5) / ly\n",
        "    anchors[:, :, :, 2] = whs[:, 0] / width\n",
        "    anchors[:, :, :, 3] = whs[:, 1] / height\n",
        "    return anchors\n",
        "\n",
        "\n",
        "def compute_loc_target(gt_box, anchors):\n",
        "    box_txty = (gt_box[:2] - anchors[..., :2]) \\\n",
        "        / anchors[..., 2:]\n",
        "    box_twth = torch.log(gt_box[2:] / anchors[..., 2:])\n",
        "    return torch.cat((box_txty, box_twth), dim=-1)\n",
        "\n",
        "\n",
        "class RefineTransform:\n",
        "\n",
        "    def __init__(self, f_anchors, num_classes, get_label=get(\"category_id\"), get_bbox=get(\"bbox\")):\n",
        "        self.f_anchors = f_anchors\n",
        "        self.num_classes = num_classes\n",
        "        self.get_label = get_label\n",
        "        self.get_bbox = get_bbox\n",
        "\n",
        "    def __call__(self, img, anns):\n",
        "        num_feature_maps = len(self.f_anchors)\n",
        "        loc_targets = []\n",
        "        cls_targets = []\n",
        "        f_anchors = []\n",
        "        for i in range(num_feature_maps):\n",
        "            anchors = self.f_anchors[i].view(-1, 4)\n",
        "            f_anchors.append(anchors)\n",
        "            num_anchors = anchors.size(0)\n",
        "            loc_targets.append(torch.zeros(num_anchors, 4))\n",
        "            cls_targets.append(torch.zeros((num_anchors,), dtype=torch.long))\n",
        "\n",
        "        for ann in anns:\n",
        "            label = self.get_label(ann) + 1\n",
        "            bbox = torch.tensor(\n",
        "                transform_bbox(\n",
        "                    self.get_bbox(ann), BBox.LTWH, BBox.XYWH))\n",
        "\n",
        "            max_ious = []\n",
        "            for anchors, loc_t, cls_t in zip(f_anchors, loc_targets, cls_targets):\n",
        "                ious = iou_1m(bbox, anchors, format=BBox.XYWH)\n",
        "                max_ious.append(ious.max(dim=0))\n",
        "\n",
        "                iou_mask = ious > 0.5\n",
        "                if iou_mask.sum() != 0:\n",
        "                    cls_t[iou_mask] = label\n",
        "                    loc_t[iou_mask] = compute_loc_target(\n",
        "                        bbox, anchors[iou_mask])\n",
        "\n",
        "            fi, (max_iou, ind) = max(\n",
        "                enumerate(max_ious), key=lambda x: x[1][0])\n",
        "            loc_targets[fi][ind] = compute_loc_target(bbox, f_anchors[fi][ind])\n",
        "            cls_targets[fi][ind] = label\n",
        "\n",
        "        return img, [loc_targets, cls_targets]\n",
        "\n",
        "\n",
        "def focal_loss2(input, target, gamma, beta, reduction='mean'):\n",
        "    target = target.unsqueeze(1)\n",
        "    logit = gamma * input.gather(1, target) + beta\n",
        "    input = input.scatter(1, target, logit)\n",
        "    return F.cross_entropy(input, target.squeeze(1), reduction=reduction) / gamma\n",
        "\n",
        "\n",
        "def binary_focal_loss2(input, target, gamma=2, beta=1, alpha=0.25, eps=1e-4, reduction='mean'):\n",
        "    xt = gamma * input + beta * (2 * target - 1)\n",
        "    eps = inverse_sigmoid(1-eps)\n",
        "    xt = torch.clamp(xt, -eps, eps)\n",
        "    return F.binary_cross_entropy_with_logits(\n",
        "        xt, target,\n",
        "        reduction=reduction,\n",
        "        pos_weight=torch.tensor(alpha)) / gamma\n",
        "\n",
        "\n",
        "class RefineLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, f_anchors, num_classes, neg_filter_threshold=0.01, p=0.01):\n",
        "        super().__init__()\n",
        "        self.f_anchors = f_anchors\n",
        "        self.num_classes = num_classes\n",
        "        self.neg_filter_threshold = inverse_sigmoid(neg_filter_threshold)\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, rps, dps, loc_targets, cls_targets):\n",
        "        batch_size = rps[0].size(0)\n",
        "        r_loc_loss = 0\n",
        "        r_cls_loss = 0\n",
        "        r_num_pos = 0\n",
        "        d_loc_loss = 0\n",
        "        d_cls_loss = 0\n",
        "        for rp, dp, loc_t, cls_t, anchors in zip(rps, dps, loc_targets, cls_targets, self.f_anchors):\n",
        "            pos = cls_t != 0\n",
        "            num_pos = pos.sum().item()\n",
        "            if num_pos == 0:\n",
        "                continue\n",
        "            r_num_pos += num_pos\n",
        "            rp = rp.permute(0, 3, 2, 1).contiguous().view(batch_size, -1, 5)\n",
        "            r_loc_p = rp[..., :4]\n",
        "            r_cls_p = rp[..., 4]\n",
        "            anchors = anchors.view(-1, 4)\n",
        "\n",
        "            r_loc_loss += F.smooth_l1_loss(\n",
        "                r_loc_p[pos], loc_t[pos], reduction='sum')\n",
        "            r_cls_loss += F.binary_cross_entropy_with_logits(\n",
        "                r_cls_p, pos.float(), reduction='sum')\n",
        "\n",
        "            r_loc_p = r_loc_p.clone().detach()\n",
        "            r_cls_p = r_cls_p.detach()\n",
        "\n",
        "            neg_filter = (~pos) & (r_cls_p > self.neg_filter_threshold)\n",
        "\n",
        "            dp = dp.permute(0, 3, 2, 1).contiguous().view(\n",
        "                batch_size, -1, 4 + self.num_classes)\n",
        "            d_loc_p = dp[..., :4]\n",
        "            d_cls_p = dp[..., 4:]\n",
        "\n",
        "            d_loc_t = loc_t - r_loc_p\n",
        "            d_loc_t[..., :2].div_(r_loc_p[..., 2:].exp_())\n",
        "\n",
        "            d_loc_loss += torch.clamp(F.smooth_l1_loss(\n",
        "                d_loc_p[pos], d_loc_t[pos], reduction='sum'), 0, num_pos)\n",
        "\n",
        "            d_cls_loss += F.cross_entropy(\n",
        "                d_cls_p[pos], cls_t[pos], reduction='sum')\n",
        "\n",
        "            d_cls_p_neg = d_cls_p[neg_filter]\n",
        "            if len(d_cls_p_neg) != 0:\n",
        "                d_cls_loss_neg = -F.log_softmax(d_cls_p_neg, dim=1)[:, 0]\n",
        "                num_neg = min(3 * num_pos, len(d_cls_p_neg))\n",
        "                d_cls_loss += torch.topk(\n",
        "                    d_cls_loss_neg, num_neg, sorted=False)[0].sum()\n",
        "\n",
        "        r_loc_loss /= r_num_pos\n",
        "        r_cls_loss /= r_num_pos\n",
        "        d_loc_loss /= r_num_pos\n",
        "        d_cls_loss /= r_num_pos\n",
        "\n",
        "        loss = r_loc_loss + r_cls_loss + d_loc_loss + d_cls_loss\n",
        "        if random.random() < self.p:\n",
        "            print(\"r_loc: %.4f | r_cls: %3.4f | d_loc: %.4f | d_cls: %.4f\" % (\n",
        "                r_loc_loss.item(), r_cls_loss.item(), d_loc_loss.item(), d_cls_loss.item()))\n",
        "        return loss\n",
        "\n",
        "\n",
        "class RefineInference:\n",
        "\n",
        "    def __init__(self, f_anchors, width, height, num_classes, neg_filter_threshold=0.01, iou_threshold=0.45, r_topk=400, d_topk=200):\n",
        "        self.f_anchors = f_anchors\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.num_classes = num_classes\n",
        "        self.neg_filter_threshold = inverse_sigmoid(neg_filter_threshold)\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.r_topk = r_topk\n",
        "        self.d_topk = d_topk\n",
        "\n",
        "    def __call__(self, rps, dps):\n",
        "        detections = []\n",
        "        batch_size = rps[0].size(0)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            boxes = []\n",
        "            confs = []\n",
        "            labels = []\n",
        "            for rp, dp, anchors in zip(rps, dps, self.f_anchors):\n",
        "                rp = rp[i].permute(2, 1, 0).contiguous().view(-1, 5)\n",
        "                r_loc_p = rp[:, :4]\n",
        "                r_cls_p = rp[:, 4]\n",
        "                anchors = anchors.view(-1, 4)\n",
        "\n",
        "                neg_filter = r_cls_p > self.neg_filter_threshold\n",
        "                r_loc_p = r_loc_p[neg_filter]\n",
        "                r_cls_p = r_cls_p[neg_filter]\n",
        "                anchors = anchors[neg_filter]\n",
        "\n",
        "                r_loc_p[:, :2].mul_(anchors[:, 2:]).add_(anchors[:, :2])\n",
        "                r_loc_p[:, 2:].exp_().mul_(anchors[:, 2:])\n",
        "\n",
        "                dp = dp[i].permute(2, 1, 0).contiguous().view(\n",
        "                    -1, 4 + self.num_classes)[neg_filter]\n",
        "                if len(dp) == 0:\n",
        "                    continue\n",
        "                d_loc_p = dp[:, :4]\n",
        "                d_cls_p = dp[:, 4:]\n",
        "                conf, label = F.softmax(d_cls_p, dim=1)[:, 1:].max(dim=1)\n",
        "\n",
        "                d_loc_p[:, :2].mul_(r_loc_p[:, 2:]).add_(r_loc_p[:, :2])\n",
        "                d_loc_p[:, 2:].exp_().mul_(r_loc_p[:, 2:])\n",
        "                d_loc_p[:, [0, 2]] *= self.width\n",
        "                d_loc_p[:, [1, 3]] *= self.height\n",
        "\n",
        "                box = d_loc_p\n",
        "\n",
        "                confs.append(conf)\n",
        "                boxes.append(box)\n",
        "                labels.append(label)\n",
        "            \n",
        "            if len(boxes) == 0:\n",
        "                continue\n",
        "\n",
        "            boxes = torch.cat(boxes, dim=0)\n",
        "            confs = torch.cat(confs, dim=0)\n",
        "            labels = torch.cat(labels, dim=0)\n",
        "\n",
        "            confs, indices = confs.topk(min(len(confs), self.r_topk))\n",
        "            boxes = boxes[indices]\n",
        "            labels = labels[indices]\n",
        "\n",
        "            boxes = transform_bboxes(\n",
        "                boxes, format=BBox.XYWH, to=BBox.LTRB, inplace=True)\n",
        "            indices = non_max_suppression(\n",
        "                boxes, confs, self.iou_threshold)\n",
        "\n",
        "            confs = confs[indices]\n",
        "            boxes = boxes[indices]\n",
        "            labels = labels[indices]\n",
        "\n",
        "            indices = confs.topk(min(len(confs), self.d_topk))[1]\n",
        "\n",
        "            for ind in indices:\n",
        "                detections.append(\n",
        "                    BBox(\n",
        "                        image_name=i,\n",
        "                        class_id=labels[ind].item(),\n",
        "                        box=boxes[ind].tolist(),\n",
        "                        confidence=confs[ind].item(),\n",
        "                        box_format=BBox.LTRB,\n",
        "                    )\n",
        "                )\n",
        "        return detections\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9jBuBw5ESdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def conv1x1(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
        "\n",
        "\n",
        "def conv3x3(in_channels, out_channels, stride=1, padding=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding)\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, expansion=4):\n",
        "        super().__init__()\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        channels = out_channels // expansion\n",
        "\n",
        "        self.conv1 = conv1x1(in_channels, channels)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = conv3x3(channels, channels, stride=stride)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv3 = conv1x1(channels, out_channels)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = conv1x1(in_channels, out_channels, stride=stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class TransferConnection(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, last=False):\n",
        "        super().__init__()\n",
        "        self.last = last\n",
        "        self.conv1 = conv3x3(in_channels, out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_channels, out_channels)\n",
        "        if not last:\n",
        "            self.deconv1 = nn.ConvTranspose2d(\n",
        "                out_channels, out_channels, 4, stride=2, padding=1)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv3 = conv3x3(out_channels, out_channels)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, x_next=None):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        if not self.last:\n",
        "            x = x + self.deconv1(x_next)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RefineDet(nn.Module):\n",
        "    def __init__(self, backbone, num_classes, num_anchors, f_channels):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = backbone.conv1\n",
        "        self.bn1 = backbone.bn1\n",
        "        self.relu = backbone.relu\n",
        "        self.maxpool = backbone.maxpool\n",
        "\n",
        "        self.layer1 = backbone.layer1\n",
        "        self.layer2 = backbone.layer2\n",
        "        self.layer3 = backbone.layer3\n",
        "        self.layer4 = backbone.layer4\n",
        "\n",
        "        stages = [\n",
        "            get_out_channels(self.layer2),\n",
        "            get_out_channels(self.layer3),\n",
        "            get_out_channels(self.layer4),\n",
        "        ]\n",
        "\n",
        "        self.layer5 = Bottleneck(stages[2], f_channels, stride=2)\n",
        "\n",
        "        self.rp1 = conv3x3(stages[0], num_anchors * (4 + 1))\n",
        "        self.rp2 = conv3x3(stages[1], num_anchors * (4 + 1))\n",
        "        self.rp3 = conv3x3(stages[2], num_anchors * (4 + 1))\n",
        "        self.rp4 = conv3x3(f_channels, num_anchors * (4 + 1))\n",
        "\n",
        "        self.tcb1 = TransferConnection(stages[0], f_channels)\n",
        "        self.tcb2 = TransferConnection(stages[1], f_channels)\n",
        "        self.tcb3 = TransferConnection(stages[2], f_channels)\n",
        "        self.tcb4 = TransferConnection(f_channels, f_channels, last=True)\n",
        "\n",
        "        self.dp1 = conv3x3(f_channels, num_anchors * (4 + num_classes))\n",
        "        self.dp2 = conv3x3(f_channels, num_anchors * (4 + num_classes))\n",
        "        self.dp3 = conv3x3(f_channels, num_anchors * (4 + num_classes))\n",
        "        self.dp4 = conv3x3(f_channels, num_anchors * (4 + num_classes))\n",
        "\n",
        "    def init_new_layers(self):\n",
        "        def init_weight(m):\n",
        "            name = type(m).__name__\n",
        "            if name.find(\"Linear\") != -1 or name.find(\"Conv\") != -1:\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        self.layer5.apply(init_weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b = x.size(0)\n",
        "        c1 = self.conv1(x)\n",
        "        c1 = self.bn1(c1)\n",
        "        c1 = self.relu(c1)\n",
        "        c2 = self.maxpool(c1)\n",
        "\n",
        "        c2 = self.layer1(c2)\n",
        "        c3 = self.layer2(c2)\n",
        "        c4 = self.layer3(c3)\n",
        "        c5 = self.layer4(c4)\n",
        "        c6 = self.layer5(c5)\n",
        "\n",
        "        rf3 = self.rp1(c3)\n",
        "        rf4 = self.rp2(c4)\n",
        "        rf5 = self.rp3(c5)\n",
        "        rf6 = self.rp4(c6)\n",
        "\n",
        "        dc6 = self.tcb4(c6)\n",
        "        dc5 = self.tcb3(c5, dc6)\n",
        "        dc4 = self.tcb2(c4, dc5)\n",
        "        dc3 = self.tcb1(c3, dc4)\n",
        "\n",
        "        df3 = self.dp1(dc3)\n",
        "        df4 = self.dp2(dc4)\n",
        "        df5 = self.dp3(dc5)\n",
        "        df6 = self.dp4(dc6)\n",
        "\n",
        "        return [rf3, rf4, rf5, rf6], [df3, df4, df5, df6]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xNpK9h-iLMQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "WIDTH = 320\n",
        "HEIGHT = 320\n",
        "STRIDES = [8, 16, 32, 64]\n",
        "LOCATIONS = [\n",
        "    (40, 40),\n",
        "    (20, 20),\n",
        "    (10, 10),\n",
        "    (5, 5),\n",
        "]\n",
        "ASPECT_RATIOS = torch.tensor([1, 2, 1/2])\n",
        "F_WHS = [\n",
        "    get_whs([4 * s, 4 * s], ASPECT_RATIOS)\n",
        "    for s in STRIDES\n",
        "]\n",
        "F_ANCHORS = [\n",
        "    get_anchors(lx, ly, whs, WIDTH, HEIGHT)\n",
        "    for (lx, ly), whs in zip(LOCATIONS, F_WHS)\n",
        "]\n",
        "NUM_CLASSES = 21\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cj2oL90kEdRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_transform = Compose([\n",
        "#     RandomChoice([\n",
        "#         UseOrigin(),\n",
        "#         RandomResizedCrop(size=(HEIGHT, WIDTH), scale=(\n",
        "#             0.1, 1), ratio=(1/2, 2), drop=True),\n",
        "#     ]),\n",
        "    Resize((HEIGHT, WIDTH)),\n",
        "    RandomHorizontalFlip(0.5),\n",
        "    ToPercentCoords(),\n",
        "    RefineTransform(F_ANCHORS, NUM_CLASSES),\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = Compose([\n",
        "    Resize((HEIGHT, WIDTH)),\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "# train_transform = Compose([\n",
        "#     RandomHorizontalFlip(),\n",
        "#     Resize(HEIGHT),\n",
        "#     CenterCrop(HEIGHT),\n",
        "#     ToPercentCoords(),\n",
        "#     RefineTransform(F_ANCHORS, NUM_CLASSES),\n",
        "#     ToTensor(),\n",
        "# ])\n",
        "\n",
        "# test_transform = Compose([\n",
        "#     Resize((HEIGHT, WIDTH)),\n",
        "#     ToTensor(),\n",
        "# ])\n",
        "\n",
        "data_home = Path(\".\")\n",
        "ds1 = VOCDetection(data_home / \"VOC\", year='2007', image_set='trainval', download=True)\n",
        "ds2 = VOCDetection(data_home / \"VOCTest\", year='2007', image_set='test', download=True)\n",
        "ds3 = VOCDetection(data_home / \"VOC\", year='2012', image_set='trainval', download=True)\n",
        "ds = ConcatDataset([ds1, ds2, ds3])\n",
        "# ds = VOCDetection(data_home, year='2012', image_set='trainval', download=True)\n",
        "# rest, ds = train_test_split(\n",
        "#     ds, test_ratio=0.01\n",
        "# )\n",
        "# ds_train = Fullset(ds, train_transform)\n",
        "# ds_val = Fullset(ds, test_transform)\n",
        "\n",
        "ds_train, ds_val = train_test_split(\n",
        "    ds, test_ratio=0.05,\n",
        "    transform=train_transform,\n",
        "    test_transform=test_transform)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "foeS-z7nSl26",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "backbone = resnet50(pretrained=True)\n",
        "del backbone.fc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aRhNUTev-_EP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "net = RefineDet(backbone, NUM_CLASSES, len(ASPECT_RATIOS), 256)\n",
        "# net.apply(init_weights(nonlinearity='relu'))\n",
        "net.init_new_layers()\n",
        "criterion = RefineLoss(cuda(F_ANCHORS), NUM_CLASSES, p=0.1)\n",
        "optimizer = SGD(filter(lambda x: x.requires_grad,\n",
        "                       net.parameters()), lr=0.001, momentum=0.9, dampening=0.9, weight_decay=5e-4)\n",
        "# optimizer = Adam(filter(lambda x: x.requires_grad,\n",
        "#                         net.parameters()), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "lr_scheduler = MultiStepLR(optimizer, [120, 160, 200], gamma=0.1)\n",
        "\n",
        "metrics = {\n",
        "    'loss': TrainLoss(),\n",
        "}\n",
        "inference = RefineInference(cuda(F_ANCHORS), WIDTH, HEIGHT, NUM_CLASSES, d_topk=200)\n",
        "test_metrics = {\n",
        "    'mAP': MeanAveragePrecision(inference)\n",
        "}\n",
        "\n",
        "\n",
        "trainer = Trainer(net, criterion, optimizer, lr_scheduler,\n",
        "                  metrics=metrics, evaluate_metrics=test_metrics,\n",
        "                  save_path=gpath(\"models\"), name=\"RefineDet-VOC2012\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Psi82frKTLRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer.load_state_dict(torch.load(gpath(\"models/RefineDet-VOC2012_trainer_11.pth\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KW02nJcKif6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "summary(net, (3,HEIGHT, WIDTH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XLC97Lb7Ehjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    ds_train, batch_size=32, shuffle=True, num_workers=1, pin_memory=True)\n",
        "val_loader = DataLoader(\n",
        "    ds_val, batch_size=48, collate_fn=box_collate_fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8eLWKtgHjjC",
        "colab_type": "code",
        "outputId": "69d6442e-9768-407f-adbd-f3e7ff11de03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4165
        }
      },
      "cell_type": "code",
      "source": [
        "hist = trainer.fit(train_loader, 10, save_per_epochs=1)\n",
        "plot_history(hist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/38\n",
            "r_loc: 0.0570 | r_cls: 2.2942 | d_loc: 0.0661 | d_cls: 3.0268\n",
            "r_loc: 0.0609 | r_cls: 2.0948 | d_loc: 0.0716 | d_cls: 2.5243\n",
            "r_loc: 0.0609 | r_cls: 2.3357 | d_loc: 0.0660 | d_cls: 2.6593\n",
            "r_loc: 0.0501 | r_cls: 2.1343 | d_loc: 0.0578 | d_cls: 2.7128\n",
            "r_loc: 0.0497 | r_cls: 2.2253 | d_loc: 0.0561 | d_cls: 2.8168\n",
            "r_loc: 0.0473 | r_cls: 2.4576 | d_loc: 0.0564 | d_cls: 3.1163\n",
            "r_loc: 0.0471 | r_cls: 2.3319 | d_loc: 0.0548 | d_cls: 3.2444\n",
            "r_loc: 0.0486 | r_cls: 2.4970 | d_loc: 0.0533 | d_cls: 3.3894\n",
            "r_loc: 0.0896 | r_cls: 2.6191 | d_loc: 0.0969 | d_cls: 2.7831\n",
            "r_loc: 0.0676 | r_cls: 2.3495 | d_loc: 0.0782 | d_cls: 2.9043\n",
            "r_loc: 0.0466 | r_cls: 2.4651 | d_loc: 0.0537 | d_cls: 2.9282\n",
            "r_loc: 0.0530 | r_cls: 2.1981 | d_loc: 0.0620 | d_cls: 3.1052\n",
            "r_loc: 0.0608 | r_cls: 2.6797 | d_loc: 0.0660 | d_cls: 3.2953\n",
            "r_loc: 0.0581 | r_cls: 2.3235 | d_loc: 0.0666 | d_cls: 2.9431\n",
            "r_loc: 0.0502 | r_cls: 2.4144 | d_loc: 0.0551 | d_cls: 2.8972\n",
            "r_loc: 0.0546 | r_cls: 2.7840 | d_loc: 0.0619 | d_cls: 2.9321\n",
            "r_loc: 0.0577 | r_cls: 3.0950 | d_loc: 0.0619 | d_cls: 3.6897\n",
            "r_loc: 0.0546 | r_cls: 2.5582 | d_loc: 0.0644 | d_cls: 3.2836\n",
            "r_loc: 0.0715 | r_cls: 2.3722 | d_loc: 0.0788 | d_cls: 2.8297\n",
            "r_loc: 0.0496 | r_cls: 2.4832 | d_loc: 0.0597 | d_cls: 3.3603\n",
            "r_loc: 0.0496 | r_cls: 2.3721 | d_loc: 0.0578 | d_cls: 2.8348\n",
            "r_loc: 0.0579 | r_cls: 2.3556 | d_loc: 0.0643 | d_cls: 3.1926\n",
            "r_loc: 0.0452 | r_cls: 2.1041 | d_loc: 0.0536 | d_cls: 2.8510\n",
            "r_loc: 0.0575 | r_cls: 2.3251 | d_loc: 0.0642 | d_cls: 3.4350\n",
            "r_loc: 0.0493 | r_cls: 2.7511 | d_loc: 0.0540 | d_cls: 2.9192\n",
            "r_loc: 0.0494 | r_cls: 2.3171 | d_loc: 0.0609 | d_cls: 2.8772\n",
            "r_loc: 0.0458 | r_cls: 2.6389 | d_loc: 0.0533 | d_cls: 3.6829\n",
            "r_loc: 0.0557 | r_cls: 2.7972 | d_loc: 0.0639 | d_cls: 2.9292\n",
            "r_loc: 0.0611 | r_cls: 3.2817 | d_loc: 0.0648 | d_cls: 3.7804\n",
            "r_loc: 0.0618 | r_cls: 2.6621 | d_loc: 0.0690 | d_cls: 3.1787\n",
            "r_loc: 0.0456 | r_cls: 2.1138 | d_loc: 0.0518 | d_cls: 2.5731\n",
            "r_loc: 0.0548 | r_cls: 2.4332 | d_loc: 0.0573 | d_cls: 3.0600\n",
            "r_loc: 0.0581 | r_cls: 2.4542 | d_loc: 0.0630 | d_cls: 2.8850\n",
            "r_loc: 0.0511 | r_cls: 2.2703 | d_loc: 0.0572 | d_cls: 2.7761\n",
            "r_loc: 0.0583 | r_cls: 2.1080 | d_loc: 0.0713 | d_cls: 2.7782\n",
            "r_loc: 0.0495 | r_cls: 2.5429 | d_loc: 0.0594 | d_cls: 2.8262\n",
            "r_loc: 0.0677 | r_cls: 2.6523 | d_loc: 0.0761 | d_cls: 3.0206\n",
            "r_loc: 0.0395 | r_cls: 2.1291 | d_loc: 0.0481 | d_cls: 2.6443\n",
            "r_loc: 0.0595 | r_cls: 2.5953 | d_loc: 0.0638 | d_cls: 3.4157\n",
            "r_loc: 0.0445 | r_cls: 2.0060 | d_loc: 0.0503 | d_cls: 2.7488\n",
            "r_loc: 0.0973 | r_cls: 3.1004 | d_loc: 0.1040 | d_cls: 3.6406\n",
            "r_loc: 0.0540 | r_cls: 2.4921 | d_loc: 0.0612 | d_cls: 2.8030\n",
            "r_loc: 0.0540 | r_cls: 2.3158 | d_loc: 0.0600 | d_cls: 3.1643\n",
            "r_loc: 0.0464 | r_cls: 2.3652 | d_loc: 0.0495 | d_cls: 2.8289\n",
            "r_loc: 0.0525 | r_cls: 2.2378 | d_loc: 0.0612 | d_cls: 2.7256\n",
            "r_loc: 0.0415 | r_cls: 2.3054 | d_loc: 0.0486 | d_cls: 2.8729\n",
            "r_loc: 0.0480 | r_cls: 2.3077 | d_loc: 0.0547 | d_cls: 2.8556\n",
            "r_loc: 0.0468 | r_cls: 2.2514 | d_loc: 0.0540 | d_cls: 2.8742\n",
            "r_loc: 0.0536 | r_cls: 2.8302 | d_loc: 0.0584 | d_cls: 3.1263\n",
            "r_loc: 0.0737 | r_cls: 2.7445 | d_loc: 0.0790 | d_cls: 3.0845\n",
            "r_loc: 0.1413 | r_cls: 3.1459 | d_loc: 0.1415 | d_cls: 3.7229\n",
            "r_loc: 0.0575 | r_cls: 3.0288 | d_loc: 0.0658 | d_cls: 3.3574\n",
            "r_loc: 0.0469 | r_cls: 2.4411 | d_loc: 0.0518 | d_cls: 3.1241\n",
            "r_loc: 0.0419 | r_cls: 2.3728 | d_loc: 0.0468 | d_cls: 3.1809\n",
            "r_loc: 0.0448 | r_cls: 2.4411 | d_loc: 0.0515 | d_cls: 2.9655\n",
            "r_loc: 0.0610 | r_cls: 2.4768 | d_loc: 0.0669 | d_cls: 2.9691\n",
            "r_loc: 0.0598 | r_cls: 2.7036 | d_loc: 0.0688 | d_cls: 2.9273\n",
            "r_loc: 0.0580 | r_cls: 2.5005 | d_loc: 0.0662 | d_cls: 3.1931\n",
            "r_loc: 0.0707 | r_cls: 2.4698 | d_loc: 0.0774 | d_cls: 2.9996\n",
            "r_loc: 0.0697 | r_cls: 2.4388 | d_loc: 0.0743 | d_cls: 2.7432\n",
            "r_loc: 0.0585 | r_cls: 2.5254 | d_loc: 0.0661 | d_cls: 2.5070\n",
            "elapsed: 1694s\tloss: 5.5559\t\n",
            "Epoch 30/38\n",
            "r_loc: 0.0483 | r_cls: 2.3296 | d_loc: 0.0567 | d_cls: 2.6687\n",
            "r_loc: 0.0693 | r_cls: 2.6381 | d_loc: 0.0752 | d_cls: 3.0683\n",
            "r_loc: 0.0486 | r_cls: 2.0305 | d_loc: 0.0565 | d_cls: 2.6940\n",
            "r_loc: 0.0487 | r_cls: 2.4668 | d_loc: 0.0543 | d_cls: 2.9297\n",
            "r_loc: 0.0531 | r_cls: 2.2095 | d_loc: 0.0602 | d_cls: 2.7647\n",
            "r_loc: 0.0503 | r_cls: 2.1859 | d_loc: 0.0571 | d_cls: 2.5693\n",
            "r_loc: 0.0491 | r_cls: 2.1142 | d_loc: 0.0563 | d_cls: 2.9319\n",
            "r_loc: 0.0611 | r_cls: 2.4638 | d_loc: 0.0685 | d_cls: 2.8873\n",
            "r_loc: 0.0548 | r_cls: 2.2422 | d_loc: 0.0602 | d_cls: 2.9489\n",
            "r_loc: 0.0410 | r_cls: 1.9876 | d_loc: 0.0470 | d_cls: 2.4371\n",
            "r_loc: 0.0523 | r_cls: 2.4624 | d_loc: 0.0628 | d_cls: 2.9005\n",
            "r_loc: 0.0691 | r_cls: 2.5956 | d_loc: 0.0753 | d_cls: 2.9532\n",
            "r_loc: 0.0401 | r_cls: 2.0085 | d_loc: 0.0482 | d_cls: 2.5279\n",
            "r_loc: 0.0487 | r_cls: 2.4152 | d_loc: 0.0596 | d_cls: 2.9509\n",
            "r_loc: 0.0664 | r_cls: 2.2922 | d_loc: 0.0704 | d_cls: 2.8493\n",
            "r_loc: 0.0434 | r_cls: 2.1276 | d_loc: 0.0509 | d_cls: 2.5919\n",
            "r_loc: 0.0498 | r_cls: 2.4865 | d_loc: 0.0593 | d_cls: 2.7670\n",
            "r_loc: 0.0678 | r_cls: 3.0025 | d_loc: 0.0725 | d_cls: 3.5730\n",
            "r_loc: 0.0635 | r_cls: 2.4779 | d_loc: 0.0722 | d_cls: 2.7560\n",
            "r_loc: 0.0683 | r_cls: 2.4153 | d_loc: 0.0748 | d_cls: 2.6462\n",
            "r_loc: 0.0537 | r_cls: 2.5288 | d_loc: 0.0618 | d_cls: 2.9264\n",
            "r_loc: 0.0495 | r_cls: 2.1457 | d_loc: 0.0551 | d_cls: 2.7039\n",
            "r_loc: 0.0446 | r_cls: 2.2884 | d_loc: 0.0502 | d_cls: 2.7466\n",
            "r_loc: 0.0708 | r_cls: 2.7553 | d_loc: 0.0761 | d_cls: 3.1844\n",
            "r_loc: 0.0556 | r_cls: 2.2778 | d_loc: 0.0647 | d_cls: 2.8720\n",
            "r_loc: 0.0601 | r_cls: 2.4573 | d_loc: 0.0706 | d_cls: 2.9025\n",
            "r_loc: 0.0655 | r_cls: 3.3548 | d_loc: 0.0718 | d_cls: 3.2479\n",
            "r_loc: 0.0550 | r_cls: 2.5552 | d_loc: 0.0609 | d_cls: 3.3928\n",
            "r_loc: 0.0599 | r_cls: 2.7090 | d_loc: 0.0704 | d_cls: 3.4044\n",
            "r_loc: 0.0460 | r_cls: 2.3370 | d_loc: 0.0532 | d_cls: 2.5991\n",
            "r_loc: 0.0652 | r_cls: 2.1979 | d_loc: 0.0727 | d_cls: 2.5035\n",
            "r_loc: 0.0349 | r_cls: 2.0321 | d_loc: 0.0431 | d_cls: 2.3893\n",
            "r_loc: 0.0535 | r_cls: 2.5625 | d_loc: 0.0594 | d_cls: 3.0469\n",
            "r_loc: 0.0499 | r_cls: 2.5814 | d_loc: 0.0595 | d_cls: 2.9405\n",
            "r_loc: 0.0535 | r_cls: 2.5059 | d_loc: 0.0624 | d_cls: 2.9096\n",
            "r_loc: 0.0602 | r_cls: 2.9263 | d_loc: 0.0685 | d_cls: 3.4146\n",
            "r_loc: 0.0519 | r_cls: 2.2452 | d_loc: 0.0587 | d_cls: 2.7571\n",
            "r_loc: 0.0565 | r_cls: 2.7723 | d_loc: 0.0610 | d_cls: 3.2711\n",
            "r_loc: 0.0691 | r_cls: 2.4717 | d_loc: 0.0760 | d_cls: 2.8562\n",
            "r_loc: 0.0464 | r_cls: 2.2872 | d_loc: 0.0535 | d_cls: 2.9192\n",
            "r_loc: 0.0495 | r_cls: 2.5773 | d_loc: 0.0548 | d_cls: 2.7229\n",
            "r_loc: 0.0505 | r_cls: 2.2935 | d_loc: 0.0564 | d_cls: 2.8348\n",
            "r_loc: 0.0631 | r_cls: 3.0420 | d_loc: 0.0720 | d_cls: 3.3910\n",
            "r_loc: 0.0711 | r_cls: 2.6954 | d_loc: 0.0755 | d_cls: 3.0579\n",
            "r_loc: 0.0624 | r_cls: 2.2475 | d_loc: 0.0697 | d_cls: 2.5536\n",
            "r_loc: 0.0475 | r_cls: 2.1012 | d_loc: 0.0571 | d_cls: 2.9120\n",
            "r_loc: 0.0664 | r_cls: 2.8123 | d_loc: 0.0710 | d_cls: 3.1610\n",
            "r_loc: 0.0626 | r_cls: 2.2567 | d_loc: 0.0677 | d_cls: 3.0685\n",
            "r_loc: 0.0468 | r_cls: 2.1350 | d_loc: 0.0567 | d_cls: 2.9923\n",
            "r_loc: 0.0535 | r_cls: 2.3912 | d_loc: 0.0596 | d_cls: 2.8366\n",
            "r_loc: 0.0569 | r_cls: 2.3884 | d_loc: 0.0654 | d_cls: 2.7257\n",
            "r_loc: 0.0536 | r_cls: 2.3317 | d_loc: 0.0597 | d_cls: 2.9370\n",
            "r_loc: 0.0659 | r_cls: 2.2424 | d_loc: 0.0723 | d_cls: 2.9119\n",
            "r_loc: 0.0605 | r_cls: 2.2924 | d_loc: 0.0663 | d_cls: 3.1806\n",
            "r_loc: 0.0549 | r_cls: 2.8165 | d_loc: 0.0594 | d_cls: 3.3918\n",
            "r_loc: 0.0621 | r_cls: 2.5679 | d_loc: 0.0693 | d_cls: 2.7860\n",
            "r_loc: 0.0556 | r_cls: 2.9187 | d_loc: 0.0623 | d_cls: 2.9211\n",
            "r_loc: 0.0582 | r_cls: 2.4874 | d_loc: 0.0652 | d_cls: 2.9060\n",
            "r_loc: 0.0544 | r_cls: 2.4420 | d_loc: 0.0596 | d_cls: 2.8103\n",
            "r_loc: 0.0435 | r_cls: 2.0365 | d_loc: 0.0485 | d_cls: 2.4064\n",
            "r_loc: 0.0517 | r_cls: 2.3275 | d_loc: 0.0565 | d_cls: 2.8746\n",
            "r_loc: 0.0422 | r_cls: 2.3717 | d_loc: 0.0502 | d_cls: 2.5299\n",
            "r_loc: 0.0732 | r_cls: 2.8414 | d_loc: 0.0770 | d_cls: 3.2611\n",
            "elapsed: 1691s\tloss: 5.4702\t\n",
            "Epoch 31/38\n",
            "r_loc: 0.0527 | r_cls: 2.5483 | d_loc: 0.0606 | d_cls: 2.7598\n",
            "r_loc: 0.0615 | r_cls: 2.3539 | d_loc: 0.0700 | d_cls: 2.9869\n",
            "r_loc: 0.0492 | r_cls: 2.5561 | d_loc: 0.0539 | d_cls: 2.9245\n",
            "r_loc: 0.0524 | r_cls: 2.4205 | d_loc: 0.0564 | d_cls: 2.8471\n",
            "r_loc: 0.0497 | r_cls: 2.4924 | d_loc: 0.0568 | d_cls: 3.0108\n",
            "r_loc: 0.0518 | r_cls: 2.0130 | d_loc: 0.0572 | d_cls: 2.4168\n",
            "r_loc: 0.0766 | r_cls: 2.1782 | d_loc: 0.0827 | d_cls: 2.4314\n",
            "r_loc: 0.0559 | r_cls: 2.4631 | d_loc: 0.0626 | d_cls: 2.7850\n",
            "r_loc: 0.0490 | r_cls: 2.4688 | d_loc: 0.0573 | d_cls: 2.6998\n",
            "r_loc: 0.0568 | r_cls: 2.2251 | d_loc: 0.0643 | d_cls: 3.0418\n",
            "r_loc: 0.0605 | r_cls: 2.5606 | d_loc: 0.0649 | d_cls: 2.9515\n",
            "r_loc: 0.0467 | r_cls: 2.3683 | d_loc: 0.0514 | d_cls: 2.7033\n",
            "r_loc: 0.0596 | r_cls: 2.6556 | d_loc: 0.0632 | d_cls: 3.0935\n",
            "r_loc: 0.0503 | r_cls: 2.1618 | d_loc: 0.0589 | d_cls: 2.5702\n",
            "r_loc: 0.0603 | r_cls: 2.4640 | d_loc: 0.0651 | d_cls: 2.6524\n",
            "r_loc: 0.0586 | r_cls: 2.5158 | d_loc: 0.0656 | d_cls: 2.8117\n",
            "r_loc: 0.0585 | r_cls: 2.3204 | d_loc: 0.0645 | d_cls: 2.6543\n",
            "r_loc: 0.0771 | r_cls: 2.5676 | d_loc: 0.0817 | d_cls: 3.2423\n",
            "r_loc: 0.0476 | r_cls: 2.1896 | d_loc: 0.0571 | d_cls: 2.8695\n",
            "r_loc: 0.0427 | r_cls: 2.0333 | d_loc: 0.0487 | d_cls: 2.3754\n",
            "r_loc: 0.0488 | r_cls: 2.2161 | d_loc: 0.0586 | d_cls: 2.7414\n",
            "r_loc: 0.0413 | r_cls: 1.8772 | d_loc: 0.0465 | d_cls: 2.6942\n",
            "r_loc: 0.0630 | r_cls: 2.4688 | d_loc: 0.0738 | d_cls: 3.1805\n",
            "r_loc: 0.0511 | r_cls: 2.1958 | d_loc: 0.0608 | d_cls: 2.4659\n",
            "r_loc: 0.0630 | r_cls: 2.0617 | d_loc: 0.0691 | d_cls: 2.6115\n",
            "r_loc: 0.0488 | r_cls: 2.3624 | d_loc: 0.0568 | d_cls: 2.9452\n",
            "r_loc: 0.0697 | r_cls: 3.2756 | d_loc: 0.0748 | d_cls: 3.2231\n",
            "r_loc: 0.0468 | r_cls: 2.6178 | d_loc: 0.0534 | d_cls: 2.9357\n",
            "r_loc: 0.0592 | r_cls: 2.8700 | d_loc: 0.0634 | d_cls: 3.2706\n",
            "r_loc: 0.0507 | r_cls: 2.2989 | d_loc: 0.0558 | d_cls: 2.9395\n",
            "r_loc: 0.0762 | r_cls: 2.3110 | d_loc: 0.0832 | d_cls: 3.0001\n",
            "r_loc: 0.0621 | r_cls: 2.2036 | d_loc: 0.0714 | d_cls: 2.3105\n",
            "r_loc: 0.0407 | r_cls: 2.3642 | d_loc: 0.0499 | d_cls: 2.9252\n",
            "r_loc: 0.0479 | r_cls: 2.3312 | d_loc: 0.0562 | d_cls: 2.8456\n",
            "r_loc: 0.0578 | r_cls: 2.2568 | d_loc: 0.0667 | d_cls: 2.6114\n",
            "r_loc: 0.0689 | r_cls: 2.5746 | d_loc: 0.0728 | d_cls: 3.4152\n",
            "r_loc: 0.0566 | r_cls: 2.4661 | d_loc: 0.0642 | d_cls: 2.9281\n",
            "r_loc: 0.0626 | r_cls: 2.6468 | d_loc: 0.0706 | d_cls: 3.4206\n",
            "r_loc: 0.0475 | r_cls: 2.1166 | d_loc: 0.0542 | d_cls: 2.5994\n",
            "r_loc: 0.0546 | r_cls: 2.6361 | d_loc: 0.0600 | d_cls: 2.9910\n",
            "r_loc: 0.0799 | r_cls: 2.6237 | d_loc: 0.0869 | d_cls: 3.1360\n",
            "r_loc: 0.0573 | r_cls: 2.4618 | d_loc: 0.0621 | d_cls: 2.7516\n",
            "r_loc: 0.0430 | r_cls: 2.5372 | d_loc: 0.0503 | d_cls: 2.8307\n",
            "r_loc: 0.0478 | r_cls: 2.5318 | d_loc: 0.0559 | d_cls: 2.7732\n",
            "r_loc: 0.0462 | r_cls: 2.3647 | d_loc: 0.0526 | d_cls: 2.6416\n",
            "r_loc: 0.0611 | r_cls: 2.7958 | d_loc: 0.0667 | d_cls: 3.1412\n",
            "r_loc: 0.0691 | r_cls: 2.5910 | d_loc: 0.0757 | d_cls: 3.0619\n",
            "r_loc: 0.0459 | r_cls: 2.2689 | d_loc: 0.0533 | d_cls: 2.9382\n",
            "r_loc: 0.0447 | r_cls: 2.2199 | d_loc: 0.0495 | d_cls: 2.8944\n",
            "r_loc: 0.0503 | r_cls: 2.6209 | d_loc: 0.0583 | d_cls: 2.9876\n",
            "r_loc: 0.0495 | r_cls: 2.3487 | d_loc: 0.0589 | d_cls: 3.1471\n",
            "r_loc: 0.0530 | r_cls: 2.7246 | d_loc: 0.0578 | d_cls: 3.1125\n",
            "r_loc: 0.0530 | r_cls: 2.5319 | d_loc: 0.0587 | d_cls: 3.1580\n",
            "r_loc: 0.0743 | r_cls: 2.5676 | d_loc: 0.0802 | d_cls: 2.8491\n",
            "r_loc: 0.0564 | r_cls: 2.2632 | d_loc: 0.0632 | d_cls: 2.6783\n",
            "r_loc: 0.0589 | r_cls: 2.3968 | d_loc: 0.0669 | d_cls: 3.0820\n",
            "r_loc: 0.0592 | r_cls: 2.1843 | d_loc: 0.0672 | d_cls: 2.7013\n",
            "r_loc: 0.0538 | r_cls: 2.0347 | d_loc: 0.0646 | d_cls: 2.4699\n",
            "r_loc: 0.0438 | r_cls: 2.2740 | d_loc: 0.0548 | d_cls: 2.7753\n",
            "r_loc: 0.0524 | r_cls: 2.4065 | d_loc: 0.0580 | d_cls: 3.1974\n",
            "r_loc: 0.0536 | r_cls: 2.2273 | d_loc: 0.0615 | d_cls: 3.0732\n",
            "r_loc: 0.0529 | r_cls: 2.0362 | d_loc: 0.0574 | d_cls: 2.8495\n",
            "r_loc: 0.0424 | r_cls: 1.9717 | d_loc: 0.0526 | d_cls: 2.4156\n",
            "r_loc: 0.0536 | r_cls: 2.2434 | d_loc: 0.0608 | d_cls: 2.6989\n",
            "r_loc: 0.0535 | r_cls: 2.4471 | d_loc: 0.0597 | d_cls: 3.3440\n",
            "r_loc: 0.0606 | r_cls: 2.7391 | d_loc: 0.0665 | d_cls: 3.1274\n",
            "r_loc: 0.0455 | r_cls: 1.9762 | d_loc: 0.0549 | d_cls: 2.4254\n",
            "elapsed: 1690s\tloss: 5.3878\t\n",
            "Epoch 32/38\n",
            "r_loc: 0.0509 | r_cls: 2.2059 | d_loc: 0.0619 | d_cls: 2.5244\n",
            "r_loc: 0.0653 | r_cls: 2.7479 | d_loc: 0.0734 | d_cls: 3.2479\n",
            "r_loc: 0.0551 | r_cls: 2.5725 | d_loc: 0.0609 | d_cls: 3.2173\n",
            "r_loc: 0.0666 | r_cls: 2.2940 | d_loc: 0.0757 | d_cls: 2.9248\n",
            "r_loc: 0.0566 | r_cls: 2.1092 | d_loc: 0.0654 | d_cls: 2.7704\n",
            "r_loc: 0.0422 | r_cls: 2.1387 | d_loc: 0.0492 | d_cls: 3.0525\n",
            "r_loc: 0.0528 | r_cls: 2.3624 | d_loc: 0.0572 | d_cls: 2.5821\n",
            "r_loc: 0.0609 | r_cls: 2.4433 | d_loc: 0.0707 | d_cls: 2.5638\n",
            "r_loc: 0.0471 | r_cls: 2.3667 | d_loc: 0.0534 | d_cls: 2.9883\n",
            "r_loc: 0.0660 | r_cls: 2.8454 | d_loc: 0.0766 | d_cls: 3.0416\n",
            "r_loc: 0.0488 | r_cls: 2.2404 | d_loc: 0.0566 | d_cls: 2.4794\n",
            "r_loc: 0.0477 | r_cls: 2.5456 | d_loc: 0.0533 | d_cls: 3.0375\n",
            "r_loc: 0.0556 | r_cls: 2.6105 | d_loc: 0.0647 | d_cls: 3.0096\n",
            "r_loc: 0.0473 | r_cls: 2.4563 | d_loc: 0.0541 | d_cls: 3.1369\n",
            "r_loc: 0.0449 | r_cls: 2.2239 | d_loc: 0.0530 | d_cls: 2.9245\n",
            "r_loc: 0.0675 | r_cls: 2.7276 | d_loc: 0.0760 | d_cls: 2.9098\n",
            "r_loc: 0.0416 | r_cls: 2.1476 | d_loc: 0.0501 | d_cls: 2.6168\n",
            "r_loc: 0.0431 | r_cls: 2.1092 | d_loc: 0.0520 | d_cls: 2.7150\n",
            "r_loc: 0.0647 | r_cls: 2.5588 | d_loc: 0.0706 | d_cls: 3.0076\n",
            "r_loc: 0.0433 | r_cls: 2.1910 | d_loc: 0.0499 | d_cls: 2.2708\n",
            "r_loc: 0.0514 | r_cls: 2.2011 | d_loc: 0.0587 | d_cls: 2.7074\n",
            "r_loc: 0.0586 | r_cls: 2.7115 | d_loc: 0.0637 | d_cls: 2.9154\n",
            "r_loc: 0.0763 | r_cls: 2.7540 | d_loc: 0.0875 | d_cls: 3.1969\n",
            "r_loc: 0.0500 | r_cls: 2.6673 | d_loc: 0.0560 | d_cls: 3.1287\n",
            "r_loc: 0.0514 | r_cls: 2.6474 | d_loc: 0.0555 | d_cls: 2.9038\n",
            "r_loc: 0.0703 | r_cls: 2.0457 | d_loc: 0.0774 | d_cls: 2.5181\n",
            "r_loc: 0.0522 | r_cls: 2.3035 | d_loc: 0.0629 | d_cls: 2.8019\n",
            "r_loc: 0.0690 | r_cls: 2.6586 | d_loc: 0.0732 | d_cls: 3.2864\n",
            "r_loc: 0.0721 | r_cls: 2.6262 | d_loc: 0.0805 | d_cls: 2.9931\n",
            "r_loc: 0.0507 | r_cls: 2.4374 | d_loc: 0.0594 | d_cls: 3.0401\n",
            "r_loc: 0.0533 | r_cls: 1.9954 | d_loc: 0.0613 | d_cls: 2.2072\n",
            "r_loc: 0.0483 | r_cls: 2.0839 | d_loc: 0.0547 | d_cls: 2.3849\n",
            "r_loc: 0.0489 | r_cls: 2.0501 | d_loc: 0.0612 | d_cls: 2.6253\n",
            "r_loc: 0.0935 | r_cls: 2.8783 | d_loc: 0.1000 | d_cls: 3.2226\n",
            "r_loc: 0.0574 | r_cls: 2.1858 | d_loc: 0.0629 | d_cls: 2.4577\n",
            "r_loc: 0.0529 | r_cls: 2.3760 | d_loc: 0.0604 | d_cls: 2.5816\n",
            "r_loc: 0.0521 | r_cls: 2.4016 | d_loc: 0.0595 | d_cls: 2.9130\n",
            "r_loc: 0.0494 | r_cls: 1.9727 | d_loc: 0.0533 | d_cls: 2.4007\n",
            "r_loc: 0.0511 | r_cls: 2.2019 | d_loc: 0.0564 | d_cls: 2.6153\n",
            "r_loc: 0.0504 | r_cls: 2.3756 | d_loc: 0.0606 | d_cls: 2.9334\n",
            "r_loc: 0.0451 | r_cls: 2.2494 | d_loc: 0.0537 | d_cls: 2.8097\n",
            "r_loc: 0.0511 | r_cls: 2.7104 | d_loc: 0.0602 | d_cls: 3.1735\n",
            "r_loc: 0.0599 | r_cls: 2.3743 | d_loc: 0.0670 | d_cls: 2.7099\n",
            "r_loc: 0.0590 | r_cls: 2.5641 | d_loc: 0.0671 | d_cls: 3.0546\n",
            "r_loc: 0.0678 | r_cls: 2.5785 | d_loc: 0.0744 | d_cls: 3.1782\n",
            "r_loc: 0.0699 | r_cls: 2.5408 | d_loc: 0.0796 | d_cls: 3.0200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rAIlwCVnV7nM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_history(hist):\n",
        "    for k, v in hist.items():\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(v)\n",
        "        ax.set_title(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nhAkuJcIS7i",
        "colab_type": "code",
        "outputId": "85ad0d54-0c1e-47c5-d0c0-63f2d01f516b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "%time trainer.evaluate(val_loader)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 3s, sys: 14.9 s, total: 1min 18s\n",
            "Wall time: 1min 18s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mAP': 0.44497637203287527}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "t-EO721jSQAt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_history(trainer.metric_history)\n",
        "trainer.metric_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_OQ5jpK9Sv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}