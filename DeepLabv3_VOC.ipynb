{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLabv3-VOC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3SrkiQNjxQCn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 uninstall pytorch-hrvvi-ext -y\n",
        "!pip3 install -U git+https://github.com/sbl1996/pytorch-hrvvi-ext.git\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hYoZ6GBgbagm",
        "outputId": "fb1cf98b-3ea6-4270-ce2c-fb952ddb3c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import hutil\n",
        "import matplotlib.pyplot as plt\n",
        "print(hutil.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fQPs47lgEFMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YjUdIrJusmXI",
        "outputId": "14f71c68-3e22-4135-da42-9e0082dd9055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "gdrive = \"/gdrive\"\n",
        "from google.colab import drive\n",
        "drive.mount(gdrive, force_remount=True)\n",
        "mydrive = os.path.join(gdrive, \"My Drive\")\n",
        "!ls /gdrive/My\\ Drive\n",
        "\n",
        "def gpath(p):\n",
        "    return os.path.join(mydrive, p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "'Colab Notebooks'   eng-fra.pt\t images   repo\t   weixin.pkl\n",
            " datasets\t    fonts\t models   result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nj37eIuqn3Mt",
        "colab_type": "code",
        "outputId": "2df6fb24-177b-4620-e663-a52c36357306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import copy\n",
        "from toolz import curry\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.transforms import Resize, RandomCrop, Compose, RandomHorizontalFlip\n",
        "\n",
        "from hutil import one_hot, cuda\n",
        "from hutil.train import init_weights, Trainer\n",
        "from hutil.ext.summary import summary\n",
        "from hutil.data import train_test_split, Fullset\n",
        "from hutil.train.metrics import Accuracy, TrainLoss, Loss\n",
        "from hutil.datasets import VOCSegmentation\n",
        "from hutil.transforms import Compose as HCompose\n",
        "from hutil.transforms.segmentation import SameTransform, ToTensor\n",
        "from hutil.inference import freeze\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "â–ˆ\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f9jBuBw5ESdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def last_conv(m):\n",
        "    convs = filter(lambda kv: 'conv' in kv[0], m.named_modules())\n",
        "    return max(convs, key=lambda kv: kv[0])[1]\n",
        "\n",
        "def get_out_channels(m):\n",
        "    return last_conv(m).out_channels\n",
        "\n",
        "def replace_first_conv(m, in_channels):\n",
        "    conv = m[0].conv1\n",
        "    m[0].conv1 = conv.__class__(\n",
        "        in_channels, conv.out_channels,\n",
        "        kernel_size=conv.kernel_size,\n",
        "        stride=conv.stride,\n",
        "        padding=conv.padding,\n",
        "        dilation=conv.dilation,\n",
        "        bias=conv.bias is not None\n",
        "    )\n",
        "    return m\n",
        "\n",
        "\n",
        "@curry\n",
        "def conv_to_atrous(m, rate):\n",
        "    r\"\"\"\n",
        "    Convert Conv2d to Atrous Convolution.\n",
        "    \"\"\"\n",
        "    if 'Conv2d' in type(m).__name__ and m.kernel_size != (1,1):\n",
        "        kh, kw = m.kernel_size\n",
        "        ph = int(((kh - 1) * (rate - 1) + kh - 1) / 2)\n",
        "        pw = int(((kw - 1) * (rate - 1) + kw - 1) / 2)\n",
        "        m.padding = (ph, pw)\n",
        "        m.stride = (1, 1)\n",
        "        m.dilation = (rate, rate)\n",
        "    return m\n",
        "\n",
        "\n",
        "class DeepLabV3(nn.Module):\n",
        "    def __init__(self, backbone, num_classes, multi_grid=(1,1,1)):\n",
        "        super().__init__()\n",
        "        self.conv1 = backbone.conv1\n",
        "        self.bn1 = backbone.bn1\n",
        "        self.relu = backbone.relu\n",
        "        self.maxpool = backbone.maxpool\n",
        "\n",
        "        self.layer1 = backbone.layer1\n",
        "        self.layer2 = backbone.layer2\n",
        "        self.layer3 = backbone.layer3\n",
        "        self.layer4 = backbone.layer4\n",
        "        self.layer4[0].conv1.stride = (1,1)\n",
        "        self.layer4[0].downsample[0].stride = (1,1)\n",
        "        self.layer5 = copy.deepcopy(self.layer4)\n",
        "        replace_first_conv(self.layer5, last_conv(self.layer4).out_channels)\n",
        "        self.layer5[0].downsample = None\n",
        "#         self.layer6 = copy.deepcopy(self.layer5)\n",
        "#         self.layer7 = copy.deepcopy(self.layer6)\n",
        "\n",
        "        self.fc = nn.Conv2d(get_out_channels(self.layer5), num_classes, kernel_size=1)\n",
        "\n",
        "        r = 1\n",
        "        for l in [self.layer4, self.layer5]:\n",
        "            r *= 2\n",
        "            for i, m in enumerate(l):\n",
        "                m.apply(conv_to_atrous(rate=r*multi_grid[i]))\n",
        "            l.apply(init_weights(nonlinearity='relu'))\n",
        "       \n",
        "    def base_parameters(self):\n",
        "        for l in [self.layer5]:\n",
        "            yield from l.parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.size()[2:]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "#         x = self.layer6(x)\n",
        "#         x = self.layer7(x)\n",
        "        x = self.fc(x)\n",
        "    \n",
        "        x = F.interpolate(x, size=size, mode='bilinear', align_corners=True)    \n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cj2oL90kEdRV",
        "colab_type": "code",
        "outputId": "60c5551c-e7ff-4914-c85b-1853702ac93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "WIDTH = 320\n",
        "HEIGHT = 320\n",
        "NUM_CLASSES = 20\n",
        "\n",
        "img_transform = Compose([\n",
        "    Resize(HEIGHT),\n",
        "    RandomCrop(HEIGHT),\n",
        "    RandomHorizontalFlip(),\n",
        "])\n",
        "\n",
        "transforms = HCompose([\n",
        "    SameTransform(img_transform),\n",
        "    ToTensor(NUM_CLASSES),\n",
        "])\n",
        "\n",
        "data_home = \"./VOC\"\n",
        "# ds1 = VOCDetection(data_home, year='2007', image_set='trainval', download=True)\n",
        "# ds2 = VOCDetection(data_home, year='2012', image_set='trainval', download=True)\n",
        "# ds = ConcatDataset([ds1, ds2])\n",
        "ds = VOCSegmentation(data_home, year='2012', image_set='trainaug', download=True)\n",
        "# rest, ds = train_test_split(\n",
        "#     ds, test_ratio=0.001\n",
        "# )\n",
        "# ds_train = Fullset(ds, transforms)\n",
        "# ds_val = Fullset(ds, transforms)\n",
        "\n",
        "ds_train, ds_val = train_test_split(\n",
        "    ds, 0.05, transform=transforms,\n",
        "    test_transform=transforms)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VOC found. Skip download or extract\n",
            "SBT found. Skip download or extract\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aRhNUTev-_EP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@curry\n",
        "def seg_loss(x, y, p=0.1):\n",
        "    loss = F.cross_entropy(x, y, ignore_index=255)\n",
        "    if random.random() < p:\n",
        "        print(loss.item())\n",
        "    return loss\n",
        "\n",
        "\n",
        "backbone = resnet50(True)\n",
        "del backbone.fc\n",
        "\n",
        "net = DeepLabV3(backbone, NUM_CLASSES + 1)\n",
        "freeze(backbone)\n",
        "\n",
        "criterion = seg_loss(p=0.1)\n",
        "optimizer = SGD([\n",
        "    {\"params\": filter(lambda x: x.requires_grad, net.base_parameters())},\n",
        "    {\"params\": net.fc.parameters(), \"lr\": 0.01}],\n",
        "    lr=0.001, momentum=0.9, dampening=0.9, weight_decay=5e-4)\n",
        "# optimizer = Adam(filter(lambda x: x.requires_grad,\n",
        "#                         net.parameters()), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "lr_scheduler = MultiStepLR(optimizer, [200, 250, 300], gamma=0.1)\n",
        "\n",
        "metrics = {\n",
        "    'loss': TrainLoss(),\n",
        "    'acc': Accuracy(),\n",
        "}\n",
        "\n",
        "trainer = Trainer(net, criterion, optimizer, lr_scheduler,\n",
        "                  metrics=metrics, save_path=gpath(\"models\"), name=\"DeepLabV3-VOC\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7FEhcB9x9_D",
        "colab_type": "code",
        "outputId": "527542e6-3c00-4947-c516-7e2192041057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3689
        }
      },
      "cell_type": "code",
      "source": [
        "summary(net, (3, HEIGHT, WIDTH))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 160, 160]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 160, 160]             128\n",
            "              ReLU-3         [-1, 64, 160, 160]               0\n",
            "         MaxPool2d-4           [-1, 64, 80, 80]               0\n",
            "            Conv2d-5           [-1, 64, 80, 80]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 80, 80]             128\n",
            "              ReLU-7           [-1, 64, 80, 80]               0\n",
            "            Conv2d-8           [-1, 64, 80, 80]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 80, 80]             128\n",
            "             ReLU-10           [-1, 64, 80, 80]               0\n",
            "           Conv2d-11          [-1, 256, 80, 80]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 80, 80]             512\n",
            "           Conv2d-13          [-1, 256, 80, 80]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 80, 80]             512\n",
            "             ReLU-15          [-1, 256, 80, 80]               0\n",
            "       Bottleneck-16          [-1, 256, 80, 80]               0\n",
            "           Conv2d-17           [-1, 64, 80, 80]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 80, 80]             128\n",
            "             ReLU-19           [-1, 64, 80, 80]               0\n",
            "           Conv2d-20           [-1, 64, 80, 80]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 80, 80]             128\n",
            "             ReLU-22           [-1, 64, 80, 80]               0\n",
            "           Conv2d-23          [-1, 256, 80, 80]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 80, 80]             512\n",
            "             ReLU-25          [-1, 256, 80, 80]               0\n",
            "       Bottleneck-26          [-1, 256, 80, 80]               0\n",
            "           Conv2d-27           [-1, 64, 80, 80]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 80, 80]             128\n",
            "             ReLU-29           [-1, 64, 80, 80]               0\n",
            "           Conv2d-30           [-1, 64, 80, 80]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 80, 80]             128\n",
            "             ReLU-32           [-1, 64, 80, 80]               0\n",
            "           Conv2d-33          [-1, 256, 80, 80]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 80, 80]             512\n",
            "             ReLU-35          [-1, 256, 80, 80]               0\n",
            "       Bottleneck-36          [-1, 256, 80, 80]               0\n",
            "           Conv2d-37          [-1, 128, 80, 80]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 80, 80]             256\n",
            "             ReLU-39          [-1, 128, 80, 80]               0\n",
            "           Conv2d-40          [-1, 128, 40, 40]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 40, 40]             256\n",
            "             ReLU-42          [-1, 128, 40, 40]               0\n",
            "           Conv2d-43          [-1, 512, 40, 40]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 40, 40]           1,024\n",
            "           Conv2d-45          [-1, 512, 40, 40]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 40, 40]           1,024\n",
            "             ReLU-47          [-1, 512, 40, 40]               0\n",
            "       Bottleneck-48          [-1, 512, 40, 40]               0\n",
            "           Conv2d-49          [-1, 128, 40, 40]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 40, 40]             256\n",
            "             ReLU-51          [-1, 128, 40, 40]               0\n",
            "           Conv2d-52          [-1, 128, 40, 40]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 40, 40]             256\n",
            "             ReLU-54          [-1, 128, 40, 40]               0\n",
            "           Conv2d-55          [-1, 512, 40, 40]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 40, 40]           1,024\n",
            "             ReLU-57          [-1, 512, 40, 40]               0\n",
            "       Bottleneck-58          [-1, 512, 40, 40]               0\n",
            "           Conv2d-59          [-1, 128, 40, 40]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 40, 40]             256\n",
            "             ReLU-61          [-1, 128, 40, 40]               0\n",
            "           Conv2d-62          [-1, 128, 40, 40]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 40, 40]             256\n",
            "             ReLU-64          [-1, 128, 40, 40]               0\n",
            "           Conv2d-65          [-1, 512, 40, 40]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 40, 40]           1,024\n",
            "             ReLU-67          [-1, 512, 40, 40]               0\n",
            "       Bottleneck-68          [-1, 512, 40, 40]               0\n",
            "           Conv2d-69          [-1, 128, 40, 40]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 40, 40]             256\n",
            "             ReLU-71          [-1, 128, 40, 40]               0\n",
            "           Conv2d-72          [-1, 128, 40, 40]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 40, 40]             256\n",
            "             ReLU-74          [-1, 128, 40, 40]               0\n",
            "           Conv2d-75          [-1, 512, 40, 40]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 40, 40]           1,024\n",
            "             ReLU-77          [-1, 512, 40, 40]               0\n",
            "       Bottleneck-78          [-1, 512, 40, 40]               0\n",
            "           Conv2d-79          [-1, 256, 40, 40]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 40, 40]             512\n",
            "             ReLU-81          [-1, 256, 40, 40]               0\n",
            "           Conv2d-82          [-1, 256, 20, 20]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 20, 20]             512\n",
            "             ReLU-84          [-1, 256, 20, 20]               0\n",
            "           Conv2d-85         [-1, 1024, 20, 20]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 20, 20]           2,048\n",
            "           Conv2d-87         [-1, 1024, 20, 20]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 20, 20]           2,048\n",
            "             ReLU-89         [-1, 1024, 20, 20]               0\n",
            "       Bottleneck-90         [-1, 1024, 20, 20]               0\n",
            "           Conv2d-91          [-1, 256, 20, 20]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 20, 20]             512\n",
            "             ReLU-93          [-1, 256, 20, 20]               0\n",
            "           Conv2d-94          [-1, 256, 20, 20]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 20, 20]             512\n",
            "             ReLU-96          [-1, 256, 20, 20]               0\n",
            "           Conv2d-97         [-1, 1024, 20, 20]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 20, 20]           2,048\n",
            "             ReLU-99         [-1, 1024, 20, 20]               0\n",
            "      Bottleneck-100         [-1, 1024, 20, 20]               0\n",
            "          Conv2d-101          [-1, 256, 20, 20]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 20, 20]             512\n",
            "            ReLU-103          [-1, 256, 20, 20]               0\n",
            "          Conv2d-104          [-1, 256, 20, 20]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 20, 20]             512\n",
            "            ReLU-106          [-1, 256, 20, 20]               0\n",
            "          Conv2d-107         [-1, 1024, 20, 20]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 20, 20]           2,048\n",
            "            ReLU-109         [-1, 1024, 20, 20]               0\n",
            "      Bottleneck-110         [-1, 1024, 20, 20]               0\n",
            "          Conv2d-111          [-1, 256, 20, 20]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 20, 20]             512\n",
            "            ReLU-113          [-1, 256, 20, 20]               0\n",
            "          Conv2d-114          [-1, 256, 20, 20]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 20, 20]             512\n",
            "            ReLU-116          [-1, 256, 20, 20]               0\n",
            "          Conv2d-117         [-1, 1024, 20, 20]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 20, 20]           2,048\n",
            "            ReLU-119         [-1, 1024, 20, 20]               0\n",
            "      Bottleneck-120         [-1, 1024, 20, 20]               0\n",
            "          Conv2d-121          [-1, 256, 20, 20]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 20, 20]             512\n",
            "            ReLU-123          [-1, 256, 20, 20]               0\n",
            "          Conv2d-124          [-1, 256, 20, 20]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 20, 20]             512\n",
            "            ReLU-126          [-1, 256, 20, 20]               0\n",
            "          Conv2d-127         [-1, 1024, 20, 20]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 20, 20]           2,048\n",
            "            ReLU-129         [-1, 1024, 20, 20]               0\n",
            "      Bottleneck-130         [-1, 1024, 20, 20]               0\n",
            "          Conv2d-131          [-1, 256, 20, 20]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 20, 20]             512\n",
            "            ReLU-133          [-1, 256, 20, 20]               0\n",
            "          Conv2d-134          [-1, 256, 20, 20]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 20, 20]             512\n",
            "            ReLU-136          [-1, 256, 20, 20]               0\n",
            "          Conv2d-137         [-1, 1024, 20, 20]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 20, 20]           2,048\n",
            "            ReLU-139         [-1, 1024, 20, 20]               0\n",
            "      Bottleneck-140         [-1, 1024, 20, 20]               0\n",
            "          Conv2d-141          [-1, 512, 20, 20]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-143          [-1, 512, 20, 20]               0\n",
            "          Conv2d-144          [-1, 512, 20, 20]       2,359,296\n",
            "     BatchNorm2d-145          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-146          [-1, 512, 20, 20]               0\n",
            "          Conv2d-147         [-1, 2048, 20, 20]       1,048,576\n",
            "     BatchNorm2d-148         [-1, 2048, 20, 20]           4,096\n",
            "          Conv2d-149         [-1, 2048, 20, 20]       2,097,152\n",
            "     BatchNorm2d-150         [-1, 2048, 20, 20]           4,096\n",
            "            ReLU-151         [-1, 2048, 20, 20]               0\n",
            "      Bottleneck-152         [-1, 2048, 20, 20]               0\n",
            "          Conv2d-153          [-1, 512, 20, 20]       1,048,576\n",
            "     BatchNorm2d-154          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-155          [-1, 512, 20, 20]               0\n",
            "          Conv2d-156          [-1, 512, 20, 20]       2,359,296\n",
            "     BatchNorm2d-157          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-158          [-1, 512, 20, 20]               0\n",
            "          Conv2d-159         [-1, 2048, 20, 20]       1,048,576\n",
            "     BatchNorm2d-160         [-1, 2048, 20, 20]           4,096\n",
            "            ReLU-161         [-1, 2048, 20, 20]               0\n",
            "      Bottleneck-162         [-1, 2048, 20, 20]               0\n",
            "          Conv2d-163          [-1, 512, 20, 20]       1,048,576\n",
            "     BatchNorm2d-164          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-165          [-1, 512, 20, 20]               0\n",
            "          Conv2d-166          [-1, 512, 20, 20]       2,359,296\n",
            "     BatchNorm2d-167          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-168          [-1, 512, 20, 20]               0\n",
            "          Conv2d-169         [-1, 2048, 20, 20]       1,048,576\n",
            "     BatchNorm2d-170         [-1, 2048, 20, 20]           4,096\n",
            "            ReLU-171         [-1, 2048, 20, 20]               0\n",
            "      Bottleneck-172         [-1, 2048, 20, 20]               0\n",
            "          Conv2d-173          [-1, 512, 20, 20]       1,048,576\n",
            "     BatchNorm2d-174          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-175          [-1, 512, 20, 20]               0\n",
            "          Conv2d-176          [-1, 512, 20, 20]       2,359,296\n",
            "     BatchNorm2d-177          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-178          [-1, 512, 20, 20]               0\n",
            "          Conv2d-179         [-1, 2048, 20, 20]       1,048,576\n",
            "     BatchNorm2d-180         [-1, 2048, 20, 20]           4,096\n",
            "            ReLU-181         [-1, 2048, 20, 20]               0\n",
            "      Bottleneck-182         [-1, 2048, 20, 20]               0\n",
            "          Conv2d-183          [-1, 512, 20, 20]       1,048,576\n",
            "     BatchNorm2d-184          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-185          [-1, 512, 20, 20]               0\n",
            "          Conv2d-186          [-1, 512, 20, 20]       2,359,296\n",
            "     BatchNorm2d-187          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-188          [-1, 512, 20, 20]               0\n",
            "          Conv2d-189         [-1, 2048, 20, 20]       1,048,576\n",
            "     BatchNorm2d-190         [-1, 2048, 20, 20]           4,096\n",
            "            ReLU-191         [-1, 2048, 20, 20]               0\n",
            "      Bottleneck-192         [-1, 2048, 20, 20]               0\n",
            "          Conv2d-193          [-1, 512, 20, 20]       1,048,576\n",
            "     BatchNorm2d-194          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-195          [-1, 512, 20, 20]               0\n",
            "          Conv2d-196          [-1, 512, 20, 20]       2,359,296\n",
            "     BatchNorm2d-197          [-1, 512, 20, 20]           1,024\n",
            "            ReLU-198          [-1, 512, 20, 20]               0\n",
            "          Conv2d-199         [-1, 2048, 20, 20]       1,048,576\n",
            "     BatchNorm2d-200         [-1, 2048, 20, 20]           4,096\n",
            "            ReLU-201         [-1, 2048, 20, 20]               0\n",
            "      Bottleneck-202         [-1, 2048, 20, 20]               0\n",
            "          Conv2d-203           [-1, 21, 20, 20]          43,029\n",
            "================================================================\n",
            "Total params: 36,938,837\n",
            "Trainable params: 13,430,805\n",
            "Non-trainable params: 23,508,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.17\n",
            "Forward/backward pass size (MB): 771.16\n",
            "Params size (MB): 140.91\n",
            "Estimated Total Size (MB): 913.24\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "40nflfW6aec7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer.load_state_dict(torch.load(gpath(\"models/DeepLabV3-VOC_trainer_20.pth\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nY9t2teTBJqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion.p = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XLC97Lb7Ehjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = DataLoader(\n",
        "    ds_train, batch_size=16, shuffle=True, num_workers=1, pin_memory=True)\n",
        "val_loader = DataLoader(ds_val, batch_size=32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8eLWKtgHjjC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hist = trainer.fit(train_loader, 10)\n",
        "plot_history(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAIlwCVnV7nM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_history(hist):\n",
        "    for k, v in hist.items():\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(v)\n",
        "        ax.set_title(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nhAkuJcIS7i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%time trainer.evaluate(val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHv8DLR9X37d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_class(img, class_, background_class=0):\n",
        "    return img.masked_fill((img != background_class) & (img != class_), background_class)\n",
        "\n",
        "\n",
        "def mean_iou(pred, gt, num_classes):\n",
        "    n = 0\n",
        "    miou = 0\n",
        "    for c in range(num_classes):\n",
        "        class_gt = extract_class(gt, c)\n",
        "        class_pred = extract_class(pred, c)\n",
        "        class_iou = class_seg_iou(pred, gt, c)\n",
        "        if class_iou is not None:\n",
        "            print(c)\n",
        "            print(class_iou)\n",
        "            n += 1\n",
        "            miou += class_iou\n",
        "    return miou / n\n",
        "\n",
        "\n",
        "def class_seg_iou(pred, gt, class_):\n",
        "    tp = ((gt == class_) & (pred == class_)).sum().item()\n",
        "    fn = ((gt == class_) & (pred != class_)).sum().item()\n",
        "    fp = ((gt != class_) & (pred == class_)).sum().item()\n",
        "    if tp + fn == 0:\n",
        "        return None\n",
        "    else:\n",
        "        return tp / (tp + fn + fp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZEvm0UZX6bW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}