{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "SG15RsvpbZVB",
        "colab_type": "code",
        "outputId": "78a02085-3754-43ba-94c0-1d5369d366fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision arrow itchat torchsummary bidict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.6/dist-packages (0.12.1)\n",
            "Requirement already satisfied: itchat in /usr/local/lib/python3.6/dist-packages (1.3.10)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Requirement already satisfied: bidict in /usr/local/lib/python3.6/dist-packages (0.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from arrow) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from itchat) (2.18.4)\n",
            "Requirement already satisfied: pyqrcode in /usr/local/lib/python3.6/dist-packages (from itchat) (1.2.1)\n",
            "Requirement already satisfied: pypng in /usr/local/lib/python3.6/dist-packages (from itchat) (0.0.18)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->itchat) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->itchat) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->itchat) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->itchat) (2018.11.29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hYoZ6GBgbagm",
        "colab_type": "code",
        "outputId": "4f945994-609c-4ad7-ab67-7680d842c1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YjUdIrJusmXI",
        "colab_type": "code",
        "outputId": "f7382f4f-35b7-46c3-c129-17f8b0bc0c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "gdrive = \"/gdrive\"\n",
        "from google.colab import drive\n",
        "drive.mount(gdrive, force_remount=True)\n",
        "mydrive = os.path.join(gdrive, \"My Drive\")\n",
        "!ls /gdrive/My\\ Drive\n",
        "\n",
        "def gpath(p):\n",
        "    return os.path.join(mydrive, p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "'Colab Notebooks'   data  'Hutil (1)'   models\t result   weixin.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nIVkrRei7dvd",
        "colab_type": "code",
        "outputId": "0d56b5cd-3a6b-4a75-a4c2-f11aa9b07348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "sys.path.append(gpath(\"Hutil (1)\"))\n",
        "import hutil"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "â–ˆ\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M3-rIBqDz8-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from hutil import Vocab, pad_sequence, train_test_split, cuda, Trainer, lmap\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1n0rH69vBww",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iq_D_x5N8PaY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "def readPairs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    with open(gpath('data/nlp_data/%s-%s.txt' % (lang1, lang2))) as f:\n",
        "        lines = f.read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "    return pairs\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        "    \"do you\", \"are you\",\n",
        "    \"i hope\", \"i have\"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    pairs = readPairs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    vocab1 = Vocab(tokens=[\"UNK\", \"SOS\", \"EOS\"], name=lang2)\n",
        "    vocab2 = Vocab(tokens=[\"UNK\", \"SOS\", \"EOS\"], name=lang1)\n",
        "    for pair in pairs:\n",
        "        vocab1.add(pair[0].split())\n",
        "        vocab2.add(pair[1].split())\n",
        "    print(\"Counted words:\")\n",
        "    print(vocab1.name, vocab1.vocab_size())\n",
        "    print(vocab2.name, vocab2.vocab_size())\n",
        "    return vocab1, vocab2, pairs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2Wq9M7f8Yno",
        "colab_type": "code",
        "outputId": "b9f9300c-c1e2-44ab-fb68-1792d79d94a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "SOS_token = 1\n",
        "EOS_token = 2\n",
        "vocab1, vocab2, pairs = prepareData('eng', 'fra', reverse=True)\n",
        "\n",
        "\n",
        "def pairs_to_tensors(pairs):\n",
        "    encoder_inputs = []\n",
        "    decoder_inputs = []\n",
        "    targets = []\n",
        "    for p in pairs:\n",
        "        src, dst = p\n",
        "        src_tokens = src.split()\n",
        "        dst_tokens = dst.split()\n",
        "        encoder_inputs.append(vocab1.as_tensor([\"SOS\"] + src_tokens))\n",
        "        decoder_inputs.append(vocab2.as_tensor(['SOS'] + dst_tokens))\n",
        "        targets.append(vocab2.as_tensor(dst_tokens + ['EOS']))\n",
        "    encoder_inputs = pad_sequence(\n",
        "        encoder_inputs, batch_first=True, padding='pre')\n",
        "    decoder_inputs = pad_sequence(\n",
        "        decoder_inputs, batch_first=True, padding='post')\n",
        "    targets = pad_sequence(targets, batch_first=True, padding='post')\n",
        "    return encoder_inputs, decoder_inputs, targets\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 13089 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4927\n",
            "eng 3246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wOlFI-tkr1k4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 150\n",
        "hidden_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NVBgYUDu8aiw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1, x2, y = pairs_to_tensors(pairs)\n",
        "x1_len = x1.size(1)\n",
        "dataset = TensorDataset(x1, x2, y)\n",
        "train_dataset, test_dataset = train_test_split(dataset, 0.3)\n",
        "test_dataset, val_dataset = train_test_split(test_dataset, 0.3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqwmPgc_8f6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "    r\"\"\"\n",
        "    Inputs: x\n",
        "        - **x** of shape `(batch, seq_len, input_size)`\n",
        "    Outputs: out, h_n\n",
        "        - **out** of shape `(batch, seq_len, num_directions * hidden_size)`\n",
        "        - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, EMBEDDING_DIM)\n",
        "        self.rnn = nn.GRU(EMBEDDING_DIM, hidden_size,\n",
        "                          bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out, h = self.rnn(out)\n",
        "        return out, h\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    r\"\"\"\n",
        "    Inputs: x, h\n",
        "        - **x** of shape `(batch, seq_len)`: teacher-forcing word indexes with post padding\n",
        "        - **h** of shape `(1, batch, hidden_size)`: context from encoder\n",
        "    Outputs: outs\n",
        "        - **outs** of shape `(batch, seq_len, output_size)`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, EMBEDDING_DIM)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.rnn = nn.GRU(EMBEDDING_DIM, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, h, teacher_forcing_ratio=0.5):\n",
        "        batch_size, seq_len = x.shape\n",
        "        outs = h.new_empty(batch_size, seq_len, self.hidden_size)\n",
        "        if random.random() < teacher_forcing_ratio:\n",
        "            x = self.embedding(x)\n",
        "            x = self.dropout(x)\n",
        "            for i in range(seq_len):\n",
        "                out, h = self.rnn(x[:, [i]], h)\n",
        "\n",
        "                outs[:, i] = out[:, 0]\n",
        "        else:\n",
        "            x = x.new_full((batch_size, 1), SOS_token)\n",
        "            for i in range(seq_len):\n",
        "                x = self.embedding(x)\n",
        "                x = self.dropout(x)\n",
        "                out, h = self.rnn(x, h)\n",
        "\n",
        "                outs[:, i] = out[:, 0]\n",
        "                out = self.fc(out.detach())\n",
        "                topv, topi = out.topk(1)\n",
        "                x = topi.squeeze(1)\n",
        "        outs = self.fc(outs)\n",
        "        return outs\n",
        "\n",
        "\n",
        "class AttnDecoder(nn.Module):\n",
        "    r\"\"\"\n",
        "    Inputs: x, h\n",
        "        - **x** of shape `(batch, seq_len)`: teacher-forcing word indexes with post padding\n",
        "        - **h** of shape `(1, batch, hidden_size)`: context from encoder\n",
        "    Outputs: outs\n",
        "        - **outs** of shape `(batch, seq_len, output_size)`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size, output_size, max_len, teacher_forcing_ratio=0.5):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, EMBEDDING_DIM)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.attn = nn.Linear(hidden_size + EMBEDDING_DIM, max_len)\n",
        "        self.attn_combine = nn.Linear(\n",
        "            hidden_size + EMBEDDING_DIM, hidden_size)\n",
        "        self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def apply_attention(self, x, h, encoder_outputs, return_weights=False):\n",
        "        attn_weights = self.attn(\n",
        "            torch.cat((x, h.transpose(0, 1)), dim=2))\n",
        "        attn_weights = torch.softmax(attn_weights, dim=2)\n",
        "        attn_applied = torch.bmm(attn_weights, encoder_outputs)\n",
        "        out = torch.cat((attn_applied, x), dim=2)\n",
        "        out = self.attn_combine(out)\n",
        "        out = torch.relu(out)\n",
        "        if return_weights:\n",
        "            return out, attn_weights\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "    def forward(self, x, h, encoder_outputs):\n",
        "        batch_size, seq_len = x.shape\n",
        "        outs = h.new_empty(batch_size, seq_len, self.hidden_size)\n",
        "\n",
        "        if random.random() < self.teacher_forcing_ratio:\n",
        "            x = self.embedding(x)\n",
        "            x = self.dropout(x)\n",
        "            for i in range(seq_len):\n",
        "                out = self.apply_attention(x[:, [i]], h, encoder_outputs)\n",
        "                out, h = self.rnn(out, h)\n",
        "\n",
        "                outs[:, i] = out[:, 0]\n",
        "        else:\n",
        "            x = x.new_full((batch_size, 1), SOS_token)\n",
        "            for i in range(seq_len):\n",
        "                x = self.embedding(x)\n",
        "                x = self.dropout(x)\n",
        "                out = self.apply_attention(x, h, encoder_outputs)\n",
        "                out, h = self.rnn(out, h)\n",
        "\n",
        "                outs[:, i] = out[:, 0]\n",
        "\n",
        "                out = self.fc(out.detach())\n",
        "                topv, topi = out.topk(1)\n",
        "                x = topi.squeeze(1)\n",
        "        outs = self.fc(outs)\n",
        "        return outs\n",
        "\n",
        "\n",
        "class Translator(nn.Module):\n",
        "    r\"\"\"\n",
        "    Inputs: x1, x2\n",
        "        - **x1** of shape `(batch, seq_len)`: encoder input\n",
        "        - **x2** of shape `(batch, seq_len)`: decoder input used for teacher forcing\n",
        "    Outpus: outs\n",
        "        _ **outs** of shape `(batch, seq_len, output_size)`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_size, hidden_size)\n",
        "        self.decoder = AttnDecoder(hidden_size * 2, output_size, MAX_LENGTH)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        encoder_outputs, _ = self.encoder(x1)\n",
        "        h = encoder_outputs[:, [-1]].transpose(0, 1)\n",
        "        outs = self.decoder(x2, h, encoder_outputs)\n",
        "        outs.transpose_(1, 2)\n",
        "        return outs\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFx3hKbB8msX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "net = Translator(vocab1.vocab_size(), hidden_size, vocab2.vocab_size())\n",
        "net = cuda(net)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(net.parameters(), lr=0.001)\n",
        "lr_scheduler = LambdaLR(optimizer, lambda x: 0.96 ** x)\n",
        "trainer = Trainer(net, criterion, optimizer, lr_scheduler)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snb9gT0L8pFl",
        "colab_type": "code",
        "outputId": "bdc17757-966a-498b-95b5-e6be445cda42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "cell_type": "code",
      "source": [
        "trainer.fit(train_dataset, batch_size=32, epochs=10, val_dataset=val_dataset)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Elapsed: 17s   Loss: 0.1190   Accuracy: 9.774   Val_Acc: 7.649   Val_Loss: 1.5292\n",
            "Epoch 2/10\n",
            "Elapsed: 17s   Loss: 0.1033   Accuracy: 9.804   Val_Acc: 7.797   Val_Loss: 1.4408\n",
            "Epoch 3/10\n",
            "Elapsed: 17s   Loss: 0.0894   Accuracy: 9.832   Val_Acc: 7.824   Val_Loss: 1.4440\n",
            "Epoch 4/10\n",
            "Elapsed: 17s   Loss: 0.0800   Accuracy: 9.847   Val_Acc: 7.714   Val_Loss: 1.5151\n",
            "Epoch 5/10\n",
            "Elapsed: 17s   Loss: 0.0775   Accuracy: 9.846   Val_Acc: 7.873   Val_Loss: 1.4320\n",
            "Epoch 6/10\n",
            "Elapsed: 17s   Loss: 0.0705   Accuracy: 9.848   Val_Acc: 7.810   Val_Loss: 1.4902\n",
            "Epoch 7/10\n",
            "Elapsed: 17s   Loss: 0.0626   Accuracy: 9.866   Val_Acc: 7.603   Val_Loss: 1.6265\n",
            "Epoch 8/10\n",
            "Elapsed: 17s   Loss: 0.0590   Accuracy: 9.866   Val_Acc: 7.801   Val_Loss: 1.4999\n",
            "Epoch 9/10\n",
            "Elapsed: 17s   Loss: 0.0527   Accuracy: 9.873   Val_Acc: 7.732   Val_Loss: 1.6083\n",
            "Epoch 10/10\n",
            "Elapsed: 17s   Loss: 0.0502   Accuracy: 9.874   Val_Acc: 7.792   Val_Loss: 1.5527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.1190010215243396,\n",
              "  0.10329391207636857,\n",
              "  0.08943986993945018,\n",
              "  0.07998332268321558,\n",
              "  0.07754085540044597,\n",
              "  0.07052769821513619,\n",
              "  0.06262119921112515,\n",
              "  0.05903479323206463,\n",
              "  0.05267633210854665,\n",
              "  0.05021556797161543],\n",
              " [9.773982320200808,\n",
              "  9.804103459565644,\n",
              "  9.832369311360909,\n",
              "  9.847211611917494,\n",
              "  9.84622940085125,\n",
              "  9.847539015606243,\n",
              "  9.865764487613227,\n",
              "  9.866419294990724,\n",
              "  9.872530830514023,\n",
              "  9.874386118083597])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "tAX2t92M9FYT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def sample(net, sentence):\n",
        "    sentence = normalizeString(sentence)\n",
        "    x1 = [vocab1.as_tensor([\"SOS\"] + sentence.split())]\n",
        "    x1 = pad_sequence(x1, batch_first=True, padding='pre', max_len=x1_len)\n",
        "    encoder_outputs, _ = net.encoder(x1)\n",
        "    h = encoder_outputs[:, [-1]].transpose(0, 1)\n",
        "    \n",
        "    max_len = x1_len\n",
        "    weights = h.new_empty((max_len, max_len))\n",
        "    x = h.new_tensor([[SOS_token]], dtype=torch.long)\n",
        "    words = []\n",
        "    for i in range(max_len):\n",
        "        x = net.decoder.embedding(x)\n",
        "        out, weight = net.decoder.apply_attention(x, h, encoder_outputs, return_weights=True)\n",
        "        out, h = net.decoder.rnn(out, h)\n",
        "        weights[i] = weight[0,0]\n",
        "        x = net.decoder.fc(out)\n",
        "        x = x.topk(1)[1].squeeze(1)\n",
        "        index = x.item()\n",
        "        word = vocab2.get_token_from_index(index)\n",
        "        words.append(word)\n",
        "        if index == EOS_token:\n",
        "            break\n",
        "    return words, weights\n",
        "\n",
        "\n",
        "def beam_search_sample(net, sentence, beam_width=3):\n",
        "    sentence = normalizeString(sentence)\n",
        "    x1 = [vocab1.as_tensor([\"SOS\"] + sentence.split())]\n",
        "    x1 = pad_sequence(x1, batch_first=True, padding='pre', max_len=x1_len)\n",
        "    encoder_outputs, _ = net.encoder(x1)\n",
        "    h = encoder_outputs[:, [-1]].transpose(0, 1)\n",
        "\n",
        "    def beam_search(x, h, beam_depth):\n",
        "        x = net.decoder.embedding(x)\n",
        "        out, weights = net.decoder.apply_attention(x, h, encoder_outputs, return_weights=True)\n",
        "        out, h = net.decoder.rnn(out, h)\n",
        "        x = net.decoder.fc(out)\n",
        "        x = F.log_softmax(x, dim=-1)\n",
        "\n",
        "        if beam_depth == 1:\n",
        "            topv, topi = x.topk(1)\n",
        "            p = topv.item()\n",
        "            x = topi.squeeze(1)\n",
        "            return [x], [h], p\n",
        "        else:\n",
        "            topv, topi = x.topk(beam_width)\n",
        "            topv.squeeze_(1)\n",
        "            x = topi.squeeze(1)\n",
        "            xs = []\n",
        "            hs = []\n",
        "            for i in range(beam_width):\n",
        "                xb = x[:, [i]]\n",
        "                x_acc, h_acc, p = beam_search(xb, h, beam_depth-1)\n",
        "                xs.append([xb] + x_acc)\n",
        "                hs.append([h] + h_acc)\n",
        "                topv[0, i] += p\n",
        "            mv, mi = topv.topk(1)\n",
        "            mi = mi.item()\n",
        "            p = mv.item()\n",
        "            return xs[mi], hs[mi], mv.item()\n",
        "\n",
        "    max_len = x1_len\n",
        "    x = h.new_tensor([[SOS_token]], dtype=torch.long)\n",
        "    words = []\n",
        "    li = 0\n",
        "    while li < max_len:\n",
        "        li_beam_width = min(beam_width, max_len - li)\n",
        "        x_acc, h_acc, _ = beam_search(x, h, li_beam_width)\n",
        "        for i in range(li_beam_width):\n",
        "            index = x_acc[i].item()\n",
        "            word = vocab2.get_token_from_index(index)\n",
        "            words.append(word)\n",
        "            if index == EOS_token:\n",
        "                return words\n",
        "        x = x_acc[-1]\n",
        "        h = h_acc[-1]\n",
        "        li += li_beam_width\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IucvSO7gAqrB",
        "colab_type": "code",
        "outputId": "c9425cd1-d5a2-4af7-8ff7-bb9643f80b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "cell_type": "code",
      "source": [
        "sentence = \"Il n'est pas honnÃªte du tout.\"\n",
        "words, weights = sample(net, sentence)\n",
        "print(words)\n",
        "plt.matshow(weights.detach().cpu().numpy())\n",
        "print(beam_search_sample(net, sentence, beam_width=3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['he', 'is', 'not', 'at', 'all', 'all', '.', 'EOS']\n",
            "['he', 'is', 'not', 'at', 'all', 'all', '.', 'EOS']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAFSCAYAAAB2cI2KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTMvxngAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd11246b2b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9qZpIDq6P1uo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tensor_to_words(tensor):\n",
        "    return lmap(lambda l: lmap(vocab2.get_token_from_index, l), tensor.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CpALfcv2Q6kB",
        "colab_type": "code",
        "outputId": "a2d87059-33f8-4c03-91b9-ed02b660fbc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_loader = DataLoader(val_dataset, batch_size=3, shuffle=True)\n",
        "batch = data_loader.__iter__().next()\n",
        "*batch_x, batch_y = batch\n",
        "batch_x = [ cuda(x) for x in batch_x ]\n",
        "batch_y = cuda(batch_y)\n",
        "\n",
        "output = net(*batch_x)\n",
        "loss = criterion(output, batch_y)\n",
        "print(loss.item())\n",
        "\n",
        "print(tensor_to_words(output.argmax(1)))\n",
        "print(tensor_to_words(batch_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8249590396881104\n",
            "[['i', 'm', 'not', 'proud', 'of', 'that', '.', 'EOS', 'UNK', 'UNK'], ['i', 'm', 'happy', 'happy', '.', '.', 'EOS', 'UNK', 'UNK', 'UNK'], ['she', 'is', 'the', '.', 'EOS', '.', 'EOS', 'UNK', 'UNK', 'UNK']]\n",
            "[['i', 'am', 'not', 'proud', 'of', 'this', '.', 'EOS', 'UNK', 'UNK'], ['i', 'm', 'kind', 'of', 'happy', '.', 'EOS', 'UNK', 'UNK', 'UNK'], ['she', 's', 'upset', 'right', 'now', '.', 'EOS', 'UNK', 'UNK', 'UNK']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tuBNyhdMSp4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}